{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrapping Nigeria Rent and Sale Propety from PropertPro** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Function to extract property details\n",
    "def extract_property_details(soup):\n",
    "    properties = []\n",
    "    \n",
    "    # Find all property listings\n",
    "    listings = soup.find_all('div', class_='property-listing-grid')\n",
    "    \n",
    "    for listing in listings:\n",
    "        try:\n",
    "            # Extract price\n",
    "            price = listing.find('div', class_='pl-price').find('h3').text.strip()\n",
    "        except AttributeError:\n",
    "            price = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            # Extract title\n",
    "            title = listing.find('div', class_='pl-title').text.strip()\n",
    "        except AttributeError:\n",
    "            title = 'N/A'\n",
    "\n",
    "        try:\n",
    "            # Extract property ID\n",
    "            pid = listing.find('p').text.strip().replace(\"PID :\", \"\")\n",
    "        except AttributeError:\n",
    "            pid = 'N/A'\n",
    "\n",
    "        try:\n",
    "            # Extract number of beds and baths\n",
    "            details = listing.find('h6').text.strip()\n",
    "        except AttributeError:\n",
    "            details = 'N/A'\n",
    "        \n",
    "        properties.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'PID': pid,\n",
    "            'Details': details\n",
    "        })\n",
    "        \n",
    "    return properties\n",
    "\n",
    "# URL template (with page number placeholder)\n",
    "url_template = 'https://www.propertypro.ng/property-for-sale?page={}'\n",
    "\n",
    "# Number of pages to crawl (adjust based on the total pages)\n",
    "num_pages = 719\n",
    "\n",
    "# File to save progress\n",
    "output_file = 'propertypro_sale_listings.csv'\n",
    "last_page_file = 'last_page.txt'\n",
    "\n",
    "# List to store all scraped properties\n",
    "all_properties = []\n",
    "\n",
    "# Check if there's already a last saved page to resume from\n",
    "if os.path.exists(last_page_file):\n",
    "    with open(last_page_file, 'r') as f:\n",
    "        last_page = int(f.read().strip()) + 1\n",
    "else:\n",
    "    last_page = 1\n",
    "\n",
    "# Crawl through multiple pages, starting from the last saved page\n",
    "for page_num in range(last_page, num_pages + 1):\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    url = url_template.format(page_num)\n",
    "    \n",
    "    try:\n",
    "        # Send a GET request to fetch the HTML content\n",
    "        response = requests.get(url, timeout=10)  # Add timeout to handle slow responses\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Extract property details from the page\n",
    "            properties = extract_property_details(soup)\n",
    "            \n",
    "            # Add the scraped data to the list\n",
    "            all_properties.extend(properties)\n",
    "            \n",
    "            # Save progress every 20 pages\n",
    "            if page_num % 20 == 0:\n",
    "                df = pd.DataFrame(all_properties)\n",
    "                \n",
    "                if os.path.exists(output_file):\n",
    "                    # Append to the existing file\n",
    "                    df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    # Save as a new file\n",
    "                    df.to_csv(output_file, index=False)\n",
    "                \n",
    "                all_properties = []  # Clear list after saving\n",
    "                print(f\"Saved progress at page {page_num}.\")\n",
    "            \n",
    "            # Update last scraped page\n",
    "            with open(last_page_file, 'w') as f:\n",
    "                f.write(str(page_num))\n",
    "            \n",
    "            # Delay to avoid overloading the server\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            print(f\"Failed to fetch page {page_num}, status code: {response.status_code}\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error on page {page_num}: {e}\")\n",
    "        # Retry fetching the page after a short delay\n",
    "        time.sleep(5)\n",
    "        continue  # Skip to the next page\n",
    "\n",
    "# Final save of any remaining data\n",
    "if all_properties:\n",
    "    df = pd.DataFrame(all_properties)\n",
    "    df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    print(f\"Final data saved to '{output_file}'.\")\n",
    "\n",
    "print(\"Scraping complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Function to extract property details for rent listings\n",
    "def extract_rental_details(soup):\n",
    "    properties = []\n",
    "    \n",
    "    # Find all property listings for rent\n",
    "    listings = soup.find_all('div', class_='property-listing-grid')\n",
    "    \n",
    "    for listing in listings:\n",
    "        try:\n",
    "            # Extract price\n",
    "            price = listing.find('div', class_='pl-price').find('h3').text.strip()\n",
    "        except AttributeError:\n",
    "            price = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            # Extract title\n",
    "            title = listing.find('div', class_='pl-title').text.strip()\n",
    "        except AttributeError:\n",
    "            title = 'N/A'\n",
    "\n",
    "        try:\n",
    "            # Extract property ID\n",
    "            pid = listing.find('p').text.strip().replace(\"PID :\", \"\")\n",
    "        except AttributeError:\n",
    "            pid = 'N/A'\n",
    "\n",
    "        try:\n",
    "            # Extract number of beds and baths\n",
    "            details = listing.find('h6').text.strip()\n",
    "        except AttributeError:\n",
    "            details = 'N/A'\n",
    "        \n",
    "        properties.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'PID': pid,\n",
    "            'Details': details\n",
    "        })\n",
    "        \n",
    "    return properties\n",
    "\n",
    "# URL template for houses for rent (with page number placeholder)\n",
    "url_template = 'https://www.propertypro.ng/property-for-rent?page={}'\n",
    "\n",
    "# Number of pages to crawl (you can adjust this)\n",
    "num_pages = 293\n",
    "\n",
    "# List to store all scraped properties\n",
    "all_rental_properties = []\n",
    "\n",
    "# Crawl through multiple pages for rent listings\n",
    "for page_num in range(1, num_pages + 1):\n",
    "    print(f\"Scraping page {page_num} for rent listings...\")\n",
    "    url = url_template.format(page_num)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        rental_properties = extract_rental_details(soup)\n",
    "        all_rental_properties.extend(rental_properties)\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print(f\"Failed to fetch page {page_num}, status code: {response.status_code}\")\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df_rentals = pd.DataFrame(all_rental_properties)\n",
    "\n",
    "# Save the data into a CSV file\n",
    "df_rentals.to_csv('propertypro_rent_listings.csv', index=False)\n",
    "print(\"Data saved to 'propertypro_rent_listings.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrapping Rent and Sale Properties for Kenya**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to extract property details\n",
    "def extract_property_details(soup):\n",
    "    properties = []\n",
    "    \n",
    "    # Find all property listings\n",
    "    listings = soup.find_all('div', class_='sc_panelWrapper')\n",
    "    \n",
    "    for listing in listings:\n",
    "        try:\n",
    "            # Extract price\n",
    "            price = listing.find('div', class_='p24_price').text.strip()\n",
    "        except AttributeError:\n",
    "            price = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            # Extract title\n",
    "            title = listing.find('div', class_='p24_regularTile').text.strip()\n",
    "        except AttributeError:\n",
    "            title = 'N/A'\n",
    "\n",
    "        try:\n",
    "            # Extract property details (e.g., bedrooms, bathrooms)\n",
    "            details = listing.find('span', class_='js_listingTileImageHolder').text.strip()\n",
    "        except AttributeError:\n",
    "            details = 'N/A'\n",
    "        \n",
    "        properties.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'Details': details\n",
    "        })\n",
    "        \n",
    "    return properties\n",
    "\n",
    "# Base URL template (with placeholders for province name and ID)\n",
    "base_url = 'https://www.property24.co.ke/property-for-sale-in-{}-p{}?Page={}'\n",
    "\n",
    "# List of provinces with their associated IDs\n",
    "provinces = {\n",
    "    'mombasa': 93,\n",
    "    'kwale': 85,\n",
    "    'kilifi': 80,\n",
    "    'tana river': 105,\n",
    "    'lamu': 87,\n",
    "    'taita–taveta': 104,\n",
    "    'garissa': 73,\n",
    "    'wajir': 111,\n",
    "    'mandera': 89,\n",
    "    'marsabit': 90,\n",
    "    'isiolo': 75,\n",
    "    'meru': 91,\n",
    "    'tharaka-nithi': 106,\n",
    "    'embu': 72,\n",
    "    'kitui': 84,\n",
    "    'machakos': 66,\n",
    "    'makueni': 88,\n",
    "    'nyandarua': 100,\n",
    "    'nyeri': 101,\n",
    "    'kirinyaga': 81,\n",
    "    'muranga': 94,\n",
    "    'kiambu': 79,\n",
    "    'turkana': 108,\n",
    "    'west pokot': 112,\n",
    "    'samburu': 102,\n",
    "    'trans-nzoia': 107,\n",
    "    'uasin gishu': 109,\n",
    "    'elgeyo-marakwet': 71,\n",
    "    'nandi': 97,\n",
    "    'baringo': 67,\n",
    "    'laikipia': 86,\n",
    "    'nakuru': 96,\n",
    "    'narok': 98,\n",
    "    'kajiado': 76,\n",
    "    'kericho': 78,\n",
    "    'bomet': 68,\n",
    "    'kakamega': 77,\n",
    "    'vihiga': 110,\n",
    "    'bungoma': 69,\n",
    "    'busia': 70,\n",
    "    'siaya': 103,\n",
    "    'kisumu': 83,\n",
    "    'homa bay': 74,\n",
    "    'migori': 92,\n",
    "    'kisii': 82,\n",
    "    'nyamira': 99,\n",
    "    'nairobi': 95\n",
    "    # Add more provinces and their IDs here...\n",
    "}\n",
    "\n",
    "# File to save progress and track last page scraped for each province\n",
    "progress_file = 'scraping_progress.json'\n",
    "\n",
    "# Load progress if it exists\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, 'r') as file:\n",
    "        progress = json.load(file)\n",
    "else:\n",
    "    progress = {province: 1 for province in provinces}  # Start from page 1 for all provinces\n",
    "\n",
    "# Placeholder for all scraped properties\n",
    "all_properties = []\n",
    "\n",
    "# Function to scrape a specific province\n",
    "def scrape_province(province, province_id):\n",
    "    page_num = progress.get(province, 1)  # Start from the last saved page\n",
    "    while True:\n",
    "        print(f\"Scraping {province}, Page {page_num}...\")\n",
    "        \n",
    "        # Construct the URL with the province and page number\n",
    "        url = base_url.format(province, province_id, page_num)\n",
    "        \n",
    "        # Request the page\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "            break\n",
    "        \n",
    "        # Parse the content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract property details\n",
    "        properties = extract_property_details(soup)\n",
    "        \n",
    "        if not properties:\n",
    "            print(f\"No more listings found for {province}. Stopping at page {page_num}.\")\n",
    "            break\n",
    "        \n",
    "        # Add properties to the global list\n",
    "        all_properties.extend(properties)\n",
    "        \n",
    "        # Save progress after each page\n",
    "        progress[province] = page_num\n",
    "        with open(progress_file, 'w') as file:\n",
    "            json.dump(progress, file)\n",
    "        \n",
    "        # Save data incrementally to avoid data loss\n",
    "        pd.DataFrame(all_properties).to_csv('property24_kenya_listings.csv', index=False)\n",
    "        \n",
    "        # Check if a 'next' page link exists\n",
    "        next_button = soup.find('li', class_='pagelink')\n",
    "        if not next_button:\n",
    "            print(f\"Finished scraping {province} after {page_num} pages.\")\n",
    "            break\n",
    "        \n",
    "        # Delay between requests to avoid overloading the server\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Increment page number\n",
    "        page_num += 1\n",
    "\n",
    "# Loop through all provinces\n",
    "for province, province_id in provinces.items():\n",
    "    scrape_province(province, province_id)\n",
    "\n",
    "print(\"Scraping complete. Data saved to 'property24_kenya_listings.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping mombasa, Page 1...\n",
      "Scraping mombasa, Page 2...\n",
      "Scraping mombasa, Page 3...\n",
      "Scraping mombasa, Page 4...\n",
      "Scraping mombasa, Page 5...\n",
      "Scraping mombasa, Page 6...\n",
      "Scraping mombasa, Page 7...\n",
      "Scraping mombasa, Page 8...\n",
      "Scraping mombasa, Page 9...\n",
      "Scraping mombasa, Page 10...\n",
      "Scraping mombasa, Page 11...\n",
      "Scraping mombasa, Page 12...\n",
      "Scraping mombasa, Page 13...\n",
      "Scraping mombasa, Page 14...\n",
      "Scraping mombasa, Page 15...\n",
      "Scraping mombasa, Page 16...\n",
      "Scraping mombasa, Page 17...\n",
      "Scraping mombasa, Page 18...\n",
      "Scraping mombasa, Page 19...\n",
      "Scraping mombasa, Page 20...\n",
      "Scraping mombasa, Page 21...\n",
      "Scraping mombasa, Page 22...\n",
      "Scraping mombasa, Page 23...\n",
      "Scraping mombasa, Page 24...\n",
      "Scraping mombasa, Page 25...\n",
      "Scraping mombasa, Page 26...\n",
      "Scraping mombasa, Page 27...\n",
      "Scraping mombasa, Page 28...\n",
      "Scraping mombasa, Page 29...\n",
      "Scraping mombasa, Page 30...\n",
      "Scraping mombasa, Page 31...\n",
      "Scraping mombasa, Page 32...\n",
      "Scraping mombasa, Page 33...\n",
      "Scraping mombasa, Page 34...\n",
      "Scraping mombasa, Page 35...\n",
      "Scraping mombasa, Page 36...\n",
      "Scraping mombasa, Page 37...\n",
      "Scraping mombasa, Page 38...\n",
      "Scraping mombasa, Page 39...\n",
      "Scraping mombasa, Page 40...\n",
      "Scraping mombasa, Page 41...\n",
      "Scraping mombasa, Page 42...\n",
      "Scraping mombasa, Page 43...\n",
      "Scraping mombasa, Page 44...\n",
      "Scraping mombasa, Page 45...\n",
      "Scraping mombasa, Page 46...\n",
      "Scraping mombasa, Page 47...\n",
      "Scraping mombasa, Page 48...\n",
      "Scraping mombasa, Page 49...\n",
      "Scraping mombasa, Page 50...\n",
      "Scraping mombasa, Page 51...\n",
      "Scraping mombasa, Page 52...\n",
      "Scraping mombasa, Page 53...\n",
      "Scraping mombasa, Page 54...\n",
      "Scraping mombasa, Page 55...\n",
      "Scraping mombasa, Page 56...\n",
      "Scraping mombasa, Page 57...\n",
      "Scraping mombasa, Page 58...\n",
      "Scraping mombasa, Page 59...\n",
      "Scraping mombasa, Page 60...\n",
      "Scraping mombasa, Page 61...\n",
      "Scraping mombasa, Page 62...\n",
      "Scraping mombasa, Page 63...\n",
      "Scraping mombasa, Page 64...\n",
      "Scraping mombasa, Page 65...\n",
      "Scraping mombasa, Page 66...\n",
      "Scraping mombasa, Page 67...\n",
      "Scraping mombasa, Page 68...\n",
      "Scraping mombasa, Page 69...\n",
      "Scraping mombasa, Page 70...\n",
      "Scraping mombasa, Page 71...\n",
      "Scraping mombasa, Page 72...\n",
      "Scraping mombasa, Page 73...\n",
      "Scraping mombasa, Page 74...\n",
      "Scraping mombasa, Page 75...\n",
      "Scraping mombasa, Page 76...\n",
      "Scraping mombasa, Page 77...\n",
      "Scraping mombasa, Page 78...\n",
      "Scraping mombasa, Page 79...\n",
      "Scraping mombasa, Page 80...\n",
      "Scraping mombasa, Page 81...\n",
      "Scraping mombasa, Page 82...\n",
      "Scraping mombasa, Page 83...\n",
      "Scraping mombasa, Page 84...\n",
      "Scraping mombasa, Page 85...\n",
      "Scraping mombasa, Page 86...\n",
      "Scraping mombasa, Page 87...\n",
      "Scraping mombasa, Page 88...\n",
      "Scraping mombasa, Page 89...\n",
      "Scraping mombasa, Page 90...\n",
      "Scraping mombasa, Page 91...\n",
      "Scraping mombasa, Page 92...\n",
      "Scraping mombasa, Page 93...\n",
      "Scraping mombasa, Page 94...\n",
      "Scraping mombasa, Page 95...\n",
      "Scraping mombasa, Page 96...\n",
      "Scraping mombasa, Page 97...\n",
      "Scraping mombasa, Page 98...\n",
      "Scraping mombasa, Page 99...\n",
      "Scraping mombasa, Page 100...\n",
      "Scraping mombasa, Page 101...\n",
      "Scraping mombasa, Page 102...\n",
      "Scraping mombasa, Page 103...\n",
      "Scraping mombasa, Page 104...\n",
      "Scraping mombasa, Page 105...\n",
      "Scraping mombasa, Page 106...\n",
      "Scraping mombasa, Page 107...\n",
      "Scraping mombasa, Page 108...\n",
      "Scraping mombasa, Page 109...\n",
      "Scraping mombasa, Page 110...\n",
      "Scraping mombasa, Page 111...\n",
      "Scraping mombasa, Page 112...\n",
      "Scraping mombasa, Page 113...\n",
      "Scraping mombasa, Page 114...\n",
      "Scraping mombasa, Page 115...\n",
      "Scraping mombasa, Page 116...\n",
      "Scraping mombasa, Page 117...\n",
      "Scraping mombasa, Page 118...\n",
      "Scraping mombasa, Page 119...\n",
      "Scraping mombasa, Page 120...\n",
      "Scraping mombasa, Page 121...\n",
      "Scraping mombasa, Page 122...\n",
      "Scraping mombasa, Page 123...\n",
      "Scraping mombasa, Page 124...\n",
      "Scraping mombasa, Page 125...\n",
      "Scraping mombasa, Page 126...\n",
      "Scraping mombasa, Page 127...\n",
      "Scraping mombasa, Page 128...\n",
      "Scraping mombasa, Page 129...\n",
      "Scraping mombasa, Page 130...\n",
      "Scraping mombasa, Page 131...\n",
      "Scraping mombasa, Page 132...\n",
      "Scraping mombasa, Page 133...\n",
      "Scraping mombasa, Page 134...\n",
      "Scraping mombasa, Page 135...\n",
      "Scraping mombasa, Page 136...\n",
      "Scraping mombasa, Page 137...\n",
      "Scraping mombasa, Page 138...\n",
      "Scraping mombasa, Page 139...\n",
      "Scraping mombasa, Page 140...\n",
      "Scraping mombasa, Page 141...\n",
      "Scraping mombasa, Page 142...\n",
      "Scraping mombasa, Page 143...\n",
      "Scraping mombasa, Page 144...\n",
      "Scraping mombasa, Page 145...\n",
      "Scraping mombasa, Page 146...\n",
      "Scraping mombasa, Page 147...\n",
      "Scraping mombasa, Page 148...\n",
      "Scraping mombasa, Page 149...\n",
      "Scraping mombasa, Page 150...\n",
      "Scraping mombasa, Page 151...\n",
      "Scraping mombasa, Page 152...\n",
      "Scraping mombasa, Page 153...\n",
      "Scraping mombasa, Page 154...\n",
      "Scraping mombasa, Page 155...\n",
      "Scraping mombasa, Page 156...\n",
      "Scraping mombasa, Page 157...\n",
      "Scraping mombasa, Page 158...\n",
      "Scraping mombasa, Page 159...\n",
      "Scraping mombasa, Page 160...\n",
      "Scraping mombasa, Page 161...\n",
      "Scraping mombasa, Page 162...\n",
      "Scraping mombasa, Page 163...\n",
      "Scraping mombasa, Page 164...\n",
      "Scraping mombasa, Page 165...\n",
      "Scraping mombasa, Page 166...\n",
      "Scraping mombasa, Page 167...\n",
      "Scraping mombasa, Page 168...\n",
      "Scraping mombasa, Page 169...\n",
      "Scraping mombasa, Page 170...\n",
      "Scraping mombasa, Page 171...\n",
      "Scraping mombasa, Page 172...\n",
      "Scraping mombasa, Page 173...\n",
      "Scraping mombasa, Page 174...\n",
      "Scraping mombasa, Page 175...\n",
      "Scraping mombasa, Page 176...\n",
      "Scraping mombasa, Page 177...\n",
      "Finished scraping mombasa after 177 pages.\n",
      "Scraping kwale, Page 1...\n",
      "Finished scraping kwale after 1 pages.\n",
      "Scraping kilifi, Page 1...\n",
      "Scraping kilifi, Page 2...\n",
      "Scraping kilifi, Page 3...\n",
      "Scraping kilifi, Page 4...\n",
      "Scraping kilifi, Page 5...\n",
      "Scraping kilifi, Page 6...\n",
      "Scraping kilifi, Page 7...\n",
      "Scraping kilifi, Page 8...\n",
      "Scraping kilifi, Page 9...\n",
      "Scraping kilifi, Page 10...\n",
      "Scraping kilifi, Page 11...\n",
      "Scraping kilifi, Page 12...\n",
      "Scraping kilifi, Page 13...\n",
      "Scraping kilifi, Page 14...\n",
      "Scraping kilifi, Page 15...\n",
      "Scraping kilifi, Page 16...\n",
      "Scraping kilifi, Page 17...\n",
      "Scraping kilifi, Page 18...\n",
      "Finished scraping kilifi after 18 pages.\n",
      "Scraping tana river, Page 1...\n",
      "Finished scraping tana river after 1 pages.\n",
      "Scraping lamu, Page 1...\n",
      "Finished scraping lamu after 1 pages.\n",
      "Scraping taita–taveta, Page 1...\n",
      "No more listings found for taita–taveta. Stopping at page 1.\n",
      "Scraping garissa, Page 1...\n",
      "Finished scraping garissa after 1 pages.\n",
      "Scraping wajir, Page 1...\n",
      "Finished scraping wajir after 1 pages.\n",
      "Scraping mandera, Page 1...\n",
      "Finished scraping mandera after 1 pages.\n",
      "Scraping marsabit, Page 1...\n",
      "Finished scraping marsabit after 1 pages.\n",
      "Scraping isiolo, Page 1...\n",
      "Finished scraping isiolo after 1 pages.\n",
      "Scraping meru, Page 1...\n",
      "Finished scraping meru after 1 pages.\n",
      "Scraping tharaka-nithi, Page 1...\n",
      "Finished scraping tharaka-nithi after 1 pages.\n",
      "Scraping embu, Page 1...\n",
      "Finished scraping embu after 1 pages.\n",
      "Scraping kitui, Page 1...\n",
      "Finished scraping kitui after 1 pages.\n",
      "Scraping machakos, Page 1...\n",
      "Scraping machakos, Page 2...\n",
      "Scraping machakos, Page 3...\n",
      "Scraping machakos, Page 4...\n",
      "Scraping machakos, Page 5...\n",
      "Scraping machakos, Page 6...\n",
      "Scraping machakos, Page 7...\n",
      "Scraping machakos, Page 8...\n",
      "Scraping machakos, Page 9...\n",
      "Scraping machakos, Page 10...\n",
      "Finished scraping machakos after 10 pages.\n",
      "Scraping makueni, Page 1...\n",
      "Finished scraping makueni after 1 pages.\n",
      "Scraping nyandarua, Page 1...\n",
      "Finished scraping nyandarua after 1 pages.\n",
      "Scraping nyeri, Page 1...\n",
      "Finished scraping nyeri after 1 pages.\n",
      "Scraping kirinyaga, Page 1...\n",
      "Finished scraping kirinyaga after 1 pages.\n",
      "Scraping muranga, Page 1...\n",
      "Finished scraping muranga after 1 pages.\n",
      "Scraping kiambu, Page 1...\n",
      "Scraping kiambu, Page 2...\n",
      "Scraping kiambu, Page 3...\n",
      "Scraping kiambu, Page 4...\n",
      "Scraping kiambu, Page 5...\n",
      "Scraping kiambu, Page 6...\n",
      "Scraping kiambu, Page 7...\n",
      "Scraping kiambu, Page 8...\n",
      "Scraping kiambu, Page 9...\n",
      "Scraping kiambu, Page 10...\n",
      "Scraping kiambu, Page 11...\n",
      "Scraping kiambu, Page 12...\n",
      "Scraping kiambu, Page 13...\n",
      "Scraping kiambu, Page 14...\n",
      "Scraping kiambu, Page 15...\n",
      "Scraping kiambu, Page 16...\n",
      "Scraping kiambu, Page 17...\n",
      "Scraping kiambu, Page 18...\n",
      "Scraping kiambu, Page 19...\n",
      "Scraping kiambu, Page 20...\n",
      "Scraping kiambu, Page 21...\n",
      "Scraping kiambu, Page 22...\n",
      "Scraping kiambu, Page 23...\n",
      "Scraping kiambu, Page 24...\n",
      "Scraping kiambu, Page 25...\n",
      "Scraping kiambu, Page 26...\n",
      "Scraping kiambu, Page 27...\n",
      "Scraping kiambu, Page 28...\n",
      "Scraping kiambu, Page 29...\n",
      "Scraping kiambu, Page 30...\n",
      "Scraping kiambu, Page 31...\n",
      "Scraping kiambu, Page 32...\n",
      "Scraping kiambu, Page 33...\n",
      "Scraping kiambu, Page 34...\n",
      "Scraping kiambu, Page 35...\n",
      "Scraping kiambu, Page 36...\n",
      "Scraping kiambu, Page 37...\n",
      "Scraping kiambu, Page 38...\n",
      "Scraping kiambu, Page 39...\n",
      "Scraping kiambu, Page 40...\n",
      "Scraping kiambu, Page 41...\n",
      "Scraping kiambu, Page 42...\n",
      "Scraping kiambu, Page 43...\n",
      "Scraping kiambu, Page 44...\n",
      "Scraping kiambu, Page 45...\n",
      "Scraping kiambu, Page 46...\n",
      "Scraping kiambu, Page 47...\n",
      "Scraping kiambu, Page 48...\n",
      "Scraping kiambu, Page 49...\n",
      "Scraping kiambu, Page 50...\n",
      "Scraping kiambu, Page 51...\n",
      "Scraping kiambu, Page 52...\n",
      "Scraping kiambu, Page 53...\n",
      "Scraping kiambu, Page 54...\n",
      "Scraping kiambu, Page 55...\n",
      "Scraping kiambu, Page 56...\n",
      "Scraping kiambu, Page 57...\n",
      "Scraping kiambu, Page 58...\n",
      "Scraping kiambu, Page 59...\n",
      "Scraping kiambu, Page 60...\n",
      "Scraping kiambu, Page 61...\n",
      "Scraping kiambu, Page 62...\n",
      "Scraping kiambu, Page 63...\n",
      "Scraping kiambu, Page 64...\n",
      "Scraping kiambu, Page 65...\n",
      "Scraping kiambu, Page 66...\n",
      "Scraping kiambu, Page 67...\n",
      "Scraping kiambu, Page 68...\n",
      "Scraping kiambu, Page 69...\n",
      "Scraping kiambu, Page 70...\n",
      "Scraping kiambu, Page 71...\n",
      "Scraping kiambu, Page 72...\n",
      "Scraping kiambu, Page 73...\n",
      "Scraping kiambu, Page 74...\n",
      "Scraping kiambu, Page 75...\n",
      "Scraping kiambu, Page 76...\n",
      "Scraping kiambu, Page 77...\n",
      "Scraping kiambu, Page 78...\n",
      "Scraping kiambu, Page 79...\n",
      "Scraping kiambu, Page 80...\n",
      "Scraping kiambu, Page 81...\n",
      "Scraping kiambu, Page 82...\n",
      "Scraping kiambu, Page 83...\n",
      "Scraping kiambu, Page 84...\n",
      "Scraping kiambu, Page 85...\n",
      "Scraping kiambu, Page 86...\n",
      "Scraping kiambu, Page 87...\n",
      "Scraping kiambu, Page 88...\n",
      "Scraping kiambu, Page 89...\n",
      "Scraping kiambu, Page 90...\n",
      "Scraping kiambu, Page 91...\n",
      "Scraping kiambu, Page 92...\n",
      "Scraping kiambu, Page 93...\n",
      "Scraping kiambu, Page 94...\n",
      "Scraping kiambu, Page 95...\n",
      "Scraping kiambu, Page 96...\n",
      "Scraping kiambu, Page 97...\n",
      "Scraping kiambu, Page 98...\n",
      "Scraping kiambu, Page 99...\n",
      "Scraping kiambu, Page 100...\n",
      "Scraping kiambu, Page 101...\n",
      "Scraping kiambu, Page 102...\n",
      "Scraping kiambu, Page 103...\n",
      "Scraping kiambu, Page 104...\n",
      "Scraping kiambu, Page 105...\n",
      "Scraping kiambu, Page 106...\n",
      "Scraping kiambu, Page 107...\n",
      "Scraping kiambu, Page 108...\n",
      "Scraping kiambu, Page 109...\n",
      "Scraping kiambu, Page 110...\n",
      "Scraping kiambu, Page 111...\n",
      "Scraping kiambu, Page 112...\n",
      "Scraping kiambu, Page 113...\n",
      "Scraping kiambu, Page 114...\n",
      "Scraping kiambu, Page 115...\n",
      "Scraping kiambu, Page 116...\n",
      "Scraping kiambu, Page 117...\n",
      "Scraping kiambu, Page 118...\n",
      "Scraping kiambu, Page 119...\n",
      "Scraping kiambu, Page 120...\n",
      "Scraping kiambu, Page 121...\n",
      "Scraping kiambu, Page 122...\n",
      "Scraping kiambu, Page 123...\n",
      "Scraping kiambu, Page 124...\n",
      "Scraping kiambu, Page 125...\n",
      "Scraping kiambu, Page 126...\n",
      "Scraping kiambu, Page 127...\n",
      "Scraping kiambu, Page 128...\n",
      "Scraping kiambu, Page 129...\n",
      "Scraping kiambu, Page 130...\n",
      "Scraping kiambu, Page 131...\n",
      "Scraping kiambu, Page 132...\n",
      "Scraping kiambu, Page 133...\n",
      "Scraping kiambu, Page 134...\n",
      "Scraping kiambu, Page 135...\n",
      "Scraping kiambu, Page 136...\n",
      "Scraping kiambu, Page 137...\n",
      "Scraping kiambu, Page 138...\n",
      "Scraping kiambu, Page 139...\n",
      "Scraping kiambu, Page 140...\n",
      "Scraping kiambu, Page 141...\n",
      "Scraping kiambu, Page 142...\n",
      "Scraping kiambu, Page 143...\n",
      "Scraping kiambu, Page 144...\n",
      "Scraping kiambu, Page 145...\n",
      "Scraping kiambu, Page 146...\n",
      "Scraping kiambu, Page 147...\n",
      "Scraping kiambu, Page 148...\n",
      "Finished scraping kiambu after 148 pages.\n",
      "Scraping turkana, Page 1...\n",
      "Finished scraping turkana after 1 pages.\n",
      "Scraping west pokot, Page 1...\n",
      "Finished scraping west pokot after 1 pages.\n",
      "Scraping samburu, Page 1...\n",
      "Finished scraping samburu after 1 pages.\n",
      "Scraping trans-nzoia, Page 1...\n",
      "Finished scraping trans-nzoia after 1 pages.\n",
      "Scraping uasin gishu, Page 1...\n",
      "Scraping uasin gishu, Page 2...\n",
      "Scraping uasin gishu, Page 3...\n",
      "Scraping uasin gishu, Page 4...\n",
      "Finished scraping uasin gishu after 4 pages.\n",
      "Scraping elgeyo-marakwet, Page 1...\n",
      "Finished scraping elgeyo-marakwet after 1 pages.\n",
      "Scraping nandi, Page 1...\n",
      "Finished scraping nandi after 1 pages.\n",
      "Scraping baringo, Page 1...\n",
      "Finished scraping baringo after 1 pages.\n",
      "Scraping laikipia, Page 1...\n",
      "Finished scraping laikipia after 1 pages.\n",
      "Scraping nakuru, Page 1...\n",
      "Scraping nakuru, Page 2...\n",
      "Scraping nakuru, Page 3...\n",
      "Scraping nakuru, Page 4...\n",
      "Finished scraping nakuru after 4 pages.\n",
      "Scraping narok, Page 1...\n",
      "Finished scraping narok after 1 pages.\n",
      "Scraping kajiado, Page 1...\n",
      "Scraping kajiado, Page 2...\n",
      "Scraping kajiado, Page 3...\n",
      "Scraping kajiado, Page 4...\n",
      "Scraping kajiado, Page 5...\n",
      "Scraping kajiado, Page 6...\n",
      "Scraping kajiado, Page 7...\n",
      "Scraping kajiado, Page 8...\n",
      "Scraping kajiado, Page 9...\n",
      "Scraping kajiado, Page 10...\n",
      "Scraping kajiado, Page 11...\n",
      "Scraping kajiado, Page 12...\n",
      "Scraping kajiado, Page 13...\n",
      "Scraping kajiado, Page 14...\n",
      "Scraping kajiado, Page 15...\n",
      "Scraping kajiado, Page 16...\n",
      "Scraping kajiado, Page 17...\n",
      "Scraping kajiado, Page 18...\n",
      "Scraping kajiado, Page 19...\n",
      "Scraping kajiado, Page 20...\n",
      "Scraping kajiado, Page 21...\n",
      "Scraping kajiado, Page 22...\n",
      "Scraping kajiado, Page 23...\n",
      "Scraping kajiado, Page 24...\n",
      "Scraping kajiado, Page 25...\n",
      "Scraping kajiado, Page 26...\n",
      "Scraping kajiado, Page 27...\n",
      "Scraping kajiado, Page 28...\n",
      "Scraping kajiado, Page 29...\n",
      "Scraping kajiado, Page 30...\n",
      "Scraping kajiado, Page 31...\n",
      "Scraping kajiado, Page 32...\n",
      "Scraping kajiado, Page 33...\n",
      "Scraping kajiado, Page 34...\n",
      "Scraping kajiado, Page 35...\n",
      "Scraping kajiado, Page 36...\n",
      "Scraping kajiado, Page 37...\n",
      "Scraping kajiado, Page 38...\n",
      "Scraping kajiado, Page 39...\n",
      "Scraping kajiado, Page 40...\n",
      "Scraping kajiado, Page 41...\n",
      "Scraping kajiado, Page 42...\n",
      "Scraping kajiado, Page 43...\n",
      "Scraping kajiado, Page 44...\n",
      "Finished scraping kajiado after 44 pages.\n",
      "Scraping kericho, Page 1...\n",
      "Finished scraping kericho after 1 pages.\n",
      "Scraping bomet, Page 1...\n",
      "Finished scraping bomet after 1 pages.\n",
      "Scraping kakamega, Page 1...\n",
      "Finished scraping kakamega after 1 pages.\n",
      "Scraping vihiga, Page 1...\n",
      "Finished scraping vihiga after 1 pages.\n",
      "Scraping bungoma, Page 1...\n",
      "Finished scraping bungoma after 1 pages.\n",
      "Scraping busia, Page 1...\n",
      "Finished scraping busia after 1 pages.\n",
      "Scraping siaya, Page 1...\n",
      "Finished scraping siaya after 1 pages.\n",
      "Scraping kisumu, Page 1...\n",
      "Scraping kisumu, Page 2...\n",
      "Scraping kisumu, Page 3...\n",
      "Finished scraping kisumu after 3 pages.\n",
      "Scraping homa bay, Page 1...\n",
      "Finished scraping homa bay after 1 pages.\n",
      "Scraping migori, Page 1...\n",
      "Finished scraping migori after 1 pages.\n",
      "Scraping kisii, Page 1...\n",
      "Finished scraping kisii after 1 pages.\n",
      "Scraping nyamira, Page 1...\n",
      "Finished scraping nyamira after 1 pages.\n",
      "Scraping nairobi, Page 1...\n",
      "Scraping nairobi, Page 2...\n",
      "Scraping nairobi, Page 3...\n",
      "Scraping nairobi, Page 4...\n",
      "Scraping nairobi, Page 5...\n",
      "Scraping nairobi, Page 6...\n",
      "Scraping nairobi, Page 7...\n",
      "Scraping nairobi, Page 8...\n",
      "Scraping nairobi, Page 9...\n",
      "Scraping nairobi, Page 10...\n",
      "Scraping nairobi, Page 11...\n",
      "Scraping nairobi, Page 12...\n",
      "Scraping nairobi, Page 13...\n",
      "Scraping nairobi, Page 14...\n",
      "Scraping nairobi, Page 15...\n",
      "Scraping nairobi, Page 16...\n",
      "Scraping nairobi, Page 17...\n",
      "Scraping nairobi, Page 18...\n",
      "Scraping nairobi, Page 19...\n",
      "Scraping nairobi, Page 20...\n",
      "Scraping nairobi, Page 21...\n",
      "Scraping nairobi, Page 22...\n",
      "Scraping nairobi, Page 23...\n",
      "Scraping nairobi, Page 24...\n",
      "Scraping nairobi, Page 25...\n",
      "Scraping nairobi, Page 26...\n",
      "Scraping nairobi, Page 27...\n",
      "Scraping nairobi, Page 28...\n",
      "Scraping nairobi, Page 29...\n",
      "Scraping nairobi, Page 30...\n",
      "Scraping nairobi, Page 31...\n",
      "Scraping nairobi, Page 32...\n",
      "Scraping nairobi, Page 33...\n",
      "Scraping nairobi, Page 34...\n",
      "Scraping nairobi, Page 35...\n",
      "Scraping nairobi, Page 36...\n",
      "Scraping nairobi, Page 37...\n",
      "Scraping nairobi, Page 38...\n",
      "Scraping nairobi, Page 39...\n",
      "Scraping nairobi, Page 40...\n",
      "Scraping nairobi, Page 41...\n",
      "Scraping nairobi, Page 42...\n",
      "Scraping nairobi, Page 43...\n",
      "Scraping nairobi, Page 44...\n",
      "Scraping nairobi, Page 45...\n",
      "Scraping nairobi, Page 46...\n",
      "Scraping nairobi, Page 47...\n",
      "Scraping nairobi, Page 48...\n",
      "Scraping nairobi, Page 49...\n",
      "Scraping nairobi, Page 50...\n",
      "Scraping nairobi, Page 51...\n",
      "Scraping nairobi, Page 52...\n",
      "Scraping nairobi, Page 53...\n",
      "Scraping nairobi, Page 54...\n",
      "Scraping nairobi, Page 55...\n",
      "Scraping nairobi, Page 56...\n",
      "Scraping nairobi, Page 57...\n",
      "Scraping nairobi, Page 58...\n",
      "Scraping nairobi, Page 59...\n",
      "Scraping nairobi, Page 60...\n",
      "Scraping nairobi, Page 61...\n",
      "Scraping nairobi, Page 62...\n",
      "Scraping nairobi, Page 63...\n",
      "Scraping nairobi, Page 64...\n",
      "Scraping nairobi, Page 65...\n",
      "Scraping nairobi, Page 66...\n",
      "Scraping nairobi, Page 67...\n",
      "Scraping nairobi, Page 68...\n",
      "Scraping nairobi, Page 69...\n",
      "Scraping nairobi, Page 70...\n",
      "Scraping nairobi, Page 71...\n",
      "Scraping nairobi, Page 72...\n",
      "Scraping nairobi, Page 73...\n",
      "Scraping nairobi, Page 74...\n",
      "Scraping nairobi, Page 75...\n",
      "Scraping nairobi, Page 76...\n",
      "Scraping nairobi, Page 77...\n",
      "Scraping nairobi, Page 78...\n",
      "Scraping nairobi, Page 79...\n",
      "Scraping nairobi, Page 80...\n",
      "Scraping nairobi, Page 81...\n",
      "Scraping nairobi, Page 82...\n",
      "Scraping nairobi, Page 83...\n",
      "Scraping nairobi, Page 84...\n",
      "Scraping nairobi, Page 85...\n",
      "Scraping nairobi, Page 86...\n",
      "Scraping nairobi, Page 87...\n",
      "Scraping nairobi, Page 88...\n",
      "Scraping nairobi, Page 89...\n",
      "Scraping nairobi, Page 90...\n",
      "Scraping nairobi, Page 91...\n",
      "Scraping nairobi, Page 92...\n",
      "Scraping nairobi, Page 93...\n",
      "Scraping nairobi, Page 94...\n",
      "Scraping nairobi, Page 95...\n",
      "Scraping nairobi, Page 96...\n",
      "Scraping nairobi, Page 97...\n",
      "Scraping nairobi, Page 98...\n",
      "Scraping nairobi, Page 99...\n",
      "Scraping nairobi, Page 100...\n",
      "Scraping nairobi, Page 101...\n",
      "Scraping nairobi, Page 102...\n",
      "Scraping nairobi, Page 103...\n",
      "Scraping nairobi, Page 104...\n",
      "Scraping nairobi, Page 105...\n",
      "Scraping nairobi, Page 106...\n",
      "Scraping nairobi, Page 107...\n",
      "Scraping nairobi, Page 108...\n",
      "Scraping nairobi, Page 109...\n",
      "Scraping nairobi, Page 110...\n",
      "Scraping nairobi, Page 111...\n",
      "Scraping nairobi, Page 112...\n",
      "Scraping nairobi, Page 113...\n",
      "Scraping nairobi, Page 114...\n",
      "Scraping nairobi, Page 115...\n",
      "Scraping nairobi, Page 116...\n",
      "Scraping nairobi, Page 117...\n",
      "Scraping nairobi, Page 118...\n",
      "Scraping nairobi, Page 119...\n",
      "Scraping nairobi, Page 120...\n",
      "Scraping nairobi, Page 121...\n",
      "Scraping nairobi, Page 122...\n",
      "Scraping nairobi, Page 123...\n",
      "Scraping nairobi, Page 124...\n",
      "Scraping nairobi, Page 125...\n",
      "Scraping nairobi, Page 126...\n",
      "Scraping nairobi, Page 127...\n",
      "Scraping nairobi, Page 128...\n",
      "Scraping nairobi, Page 129...\n",
      "Scraping nairobi, Page 130...\n",
      "Scraping nairobi, Page 131...\n",
      "Scraping nairobi, Page 132...\n",
      "Scraping nairobi, Page 133...\n",
      "Scraping nairobi, Page 134...\n",
      "Scraping nairobi, Page 135...\n",
      "Scraping nairobi, Page 136...\n",
      "Scraping nairobi, Page 137...\n",
      "Scraping nairobi, Page 138...\n",
      "Scraping nairobi, Page 139...\n",
      "Scraping nairobi, Page 140...\n",
      "Scraping nairobi, Page 141...\n",
      "Scraping nairobi, Page 142...\n",
      "Scraping nairobi, Page 143...\n",
      "Scraping nairobi, Page 144...\n",
      "Scraping nairobi, Page 145...\n",
      "Scraping nairobi, Page 146...\n",
      "Scraping nairobi, Page 147...\n",
      "Scraping nairobi, Page 148...\n",
      "Scraping nairobi, Page 149...\n",
      "Scraping nairobi, Page 150...\n",
      "Scraping nairobi, Page 151...\n",
      "Scraping nairobi, Page 152...\n",
      "Scraping nairobi, Page 153...\n",
      "Scraping nairobi, Page 154...\n",
      "Scraping nairobi, Page 155...\n",
      "Scraping nairobi, Page 156...\n",
      "Scraping nairobi, Page 157...\n",
      "Scraping nairobi, Page 158...\n",
      "Scraping nairobi, Page 159...\n",
      "Scraping nairobi, Page 160...\n",
      "Scraping nairobi, Page 161...\n",
      "Scraping nairobi, Page 162...\n",
      "Scraping nairobi, Page 163...\n",
      "Scraping nairobi, Page 164...\n",
      "Scraping nairobi, Page 165...\n",
      "Scraping nairobi, Page 166...\n",
      "Scraping nairobi, Page 167...\n",
      "Scraping nairobi, Page 168...\n",
      "Scraping nairobi, Page 169...\n",
      "Scraping nairobi, Page 170...\n",
      "Scraping nairobi, Page 171...\n",
      "Scraping nairobi, Page 172...\n",
      "Scraping nairobi, Page 173...\n",
      "Scraping nairobi, Page 174...\n",
      "Scraping nairobi, Page 175...\n",
      "Scraping nairobi, Page 176...\n",
      "Scraping nairobi, Page 177...\n",
      "Scraping nairobi, Page 178...\n",
      "Scraping nairobi, Page 179...\n",
      "Scraping nairobi, Page 180...\n",
      "Scraping nairobi, Page 181...\n",
      "Scraping nairobi, Page 182...\n",
      "Scraping nairobi, Page 183...\n",
      "Scraping nairobi, Page 184...\n",
      "Scraping nairobi, Page 185...\n",
      "Scraping nairobi, Page 186...\n",
      "Scraping nairobi, Page 187...\n",
      "Scraping nairobi, Page 188...\n",
      "Scraping nairobi, Page 189...\n",
      "Scraping nairobi, Page 190...\n",
      "Scraping nairobi, Page 191...\n",
      "Scraping nairobi, Page 192...\n",
      "Scraping nairobi, Page 193...\n",
      "Scraping nairobi, Page 194...\n",
      "Scraping nairobi, Page 195...\n",
      "Scraping nairobi, Page 196...\n",
      "Scraping nairobi, Page 197...\n",
      "Scraping nairobi, Page 198...\n",
      "Scraping nairobi, Page 199...\n",
      "Scraping nairobi, Page 200...\n",
      "Scraping nairobi, Page 201...\n",
      "Scraping nairobi, Page 202...\n",
      "Scraping nairobi, Page 203...\n",
      "Scraping nairobi, Page 204...\n",
      "Scraping nairobi, Page 205...\n",
      "Scraping nairobi, Page 206...\n",
      "Scraping nairobi, Page 207...\n",
      "Scraping nairobi, Page 208...\n",
      "Scraping nairobi, Page 209...\n",
      "Scraping nairobi, Page 210...\n",
      "Scraping nairobi, Page 211...\n",
      "Scraping nairobi, Page 212...\n",
      "Scraping nairobi, Page 213...\n",
      "Scraping nairobi, Page 214...\n",
      "Scraping nairobi, Page 215...\n",
      "Scraping nairobi, Page 216...\n",
      "Scraping nairobi, Page 217...\n",
      "Scraping nairobi, Page 218...\n",
      "Scraping nairobi, Page 219...\n",
      "Scraping nairobi, Page 220...\n",
      "Scraping nairobi, Page 221...\n",
      "Scraping nairobi, Page 222...\n",
      "Scraping nairobi, Page 223...\n",
      "Scraping nairobi, Page 224...\n",
      "Scraping nairobi, Page 225...\n",
      "Scraping nairobi, Page 226...\n",
      "Scraping nairobi, Page 227...\n",
      "Scraping nairobi, Page 228...\n",
      "Scraping nairobi, Page 229...\n",
      "Scraping nairobi, Page 230...\n",
      "Scraping nairobi, Page 231...\n",
      "Scraping nairobi, Page 232...\n",
      "Scraping nairobi, Page 233...\n",
      "Scraping nairobi, Page 234...\n",
      "Scraping nairobi, Page 235...\n",
      "Scraping nairobi, Page 236...\n",
      "Scraping nairobi, Page 237...\n",
      "Scraping nairobi, Page 238...\n",
      "Scraping nairobi, Page 239...\n",
      "Scraping nairobi, Page 240...\n",
      "Scraping nairobi, Page 241...\n",
      "Scraping nairobi, Page 242...\n",
      "Scraping nairobi, Page 243...\n",
      "Scraping nairobi, Page 244...\n",
      "Scraping nairobi, Page 245...\n",
      "Scraping nairobi, Page 246...\n",
      "Scraping nairobi, Page 247...\n",
      "Scraping nairobi, Page 248...\n",
      "Scraping nairobi, Page 249...\n",
      "Scraping nairobi, Page 250...\n",
      "Scraping nairobi, Page 251...\n",
      "Scraping nairobi, Page 252...\n",
      "Scraping nairobi, Page 253...\n",
      "Scraping nairobi, Page 254...\n",
      "Scraping nairobi, Page 255...\n",
      "Scraping nairobi, Page 256...\n",
      "Scraping nairobi, Page 257...\n",
      "Scraping nairobi, Page 258...\n",
      "Scraping nairobi, Page 259...\n",
      "Scraping nairobi, Page 260...\n",
      "Scraping nairobi, Page 261...\n",
      "Scraping nairobi, Page 262...\n",
      "Scraping nairobi, Page 263...\n",
      "Scraping nairobi, Page 264...\n",
      "Scraping nairobi, Page 265...\n",
      "Scraping nairobi, Page 266...\n",
      "Scraping nairobi, Page 267...\n",
      "Scraping nairobi, Page 268...\n",
      "Scraping nairobi, Page 269...\n",
      "Scraping nairobi, Page 270...\n",
      "Scraping nairobi, Page 271...\n",
      "Scraping nairobi, Page 272...\n",
      "Scraping nairobi, Page 273...\n",
      "Scraping nairobi, Page 274...\n",
      "Scraping nairobi, Page 275...\n",
      "Scraping nairobi, Page 276...\n",
      "Scraping nairobi, Page 277...\n",
      "Scraping nairobi, Page 278...\n",
      "Scraping nairobi, Page 279...\n",
      "Scraping nairobi, Page 280...\n",
      "Scraping nairobi, Page 281...\n",
      "Scraping nairobi, Page 282...\n",
      "Scraping nairobi, Page 283...\n",
      "Scraping nairobi, Page 284...\n",
      "Scraping nairobi, Page 285...\n",
      "Scraping nairobi, Page 286...\n",
      "Scraping nairobi, Page 287...\n",
      "Scraping nairobi, Page 288...\n",
      "Scraping nairobi, Page 289...\n",
      "Scraping nairobi, Page 290...\n",
      "Scraping nairobi, Page 291...\n",
      "Scraping nairobi, Page 292...\n",
      "Scraping nairobi, Page 293...\n",
      "Scraping nairobi, Page 294...\n",
      "Scraping nairobi, Page 295...\n",
      "Scraping nairobi, Page 296...\n",
      "Scraping nairobi, Page 297...\n",
      "Scraping nairobi, Page 298...\n",
      "Scraping nairobi, Page 299...\n",
      "Scraping nairobi, Page 300...\n",
      "Scraping nairobi, Page 301...\n",
      "Scraping nairobi, Page 302...\n",
      "Scraping nairobi, Page 303...\n",
      "Scraping nairobi, Page 304...\n",
      "Scraping nairobi, Page 305...\n",
      "Scraping nairobi, Page 306...\n",
      "Scraping nairobi, Page 307...\n",
      "Scraping nairobi, Page 308...\n",
      "Scraping nairobi, Page 309...\n",
      "Scraping nairobi, Page 310...\n",
      "Scraping nairobi, Page 311...\n",
      "Scraping nairobi, Page 312...\n",
      "Scraping nairobi, Page 313...\n",
      "Scraping nairobi, Page 314...\n",
      "Scraping nairobi, Page 315...\n",
      "Scraping nairobi, Page 316...\n",
      "Scraping nairobi, Page 317...\n",
      "Scraping nairobi, Page 318...\n",
      "Scraping nairobi, Page 319...\n",
      "Scraping nairobi, Page 320...\n",
      "Scraping nairobi, Page 321...\n",
      "Scraping nairobi, Page 322...\n",
      "Scraping nairobi, Page 323...\n",
      "Scraping nairobi, Page 324...\n",
      "Scraping nairobi, Page 325...\n",
      "Scraping nairobi, Page 326...\n",
      "Scraping nairobi, Page 327...\n",
      "Scraping nairobi, Page 328...\n",
      "Scraping nairobi, Page 329...\n",
      "Scraping nairobi, Page 330...\n",
      "Scraping nairobi, Page 331...\n",
      "Scraping nairobi, Page 332...\n",
      "Scraping nairobi, Page 333...\n",
      "Scraping nairobi, Page 334...\n",
      "Scraping nairobi, Page 335...\n",
      "Scraping nairobi, Page 336...\n",
      "Scraping nairobi, Page 337...\n",
      "Scraping nairobi, Page 338...\n",
      "Scraping nairobi, Page 339...\n",
      "Scraping nairobi, Page 340...\n",
      "Scraping nairobi, Page 341...\n",
      "Scraping nairobi, Page 342...\n",
      "Scraping nairobi, Page 343...\n",
      "Scraping nairobi, Page 344...\n",
      "Scraping nairobi, Page 345...\n",
      "Scraping nairobi, Page 346...\n",
      "Scraping nairobi, Page 347...\n",
      "Scraping nairobi, Page 348...\n",
      "Scraping nairobi, Page 349...\n",
      "Scraping nairobi, Page 350...\n",
      "Scraping nairobi, Page 351...\n",
      "Scraping nairobi, Page 352...\n",
      "Scraping nairobi, Page 353...\n",
      "Scraping nairobi, Page 354...\n",
      "Scraping nairobi, Page 355...\n",
      "Scraping nairobi, Page 356...\n",
      "Scraping nairobi, Page 357...\n",
      "Scraping nairobi, Page 358...\n",
      "Scraping nairobi, Page 359...\n",
      "Scraping nairobi, Page 360...\n",
      "Scraping nairobi, Page 361...\n",
      "Scraping nairobi, Page 362...\n",
      "Scraping nairobi, Page 363...\n",
      "Scraping nairobi, Page 364...\n",
      "Scraping nairobi, Page 365...\n",
      "Scraping nairobi, Page 366...\n",
      "Scraping nairobi, Page 367...\n",
      "Scraping nairobi, Page 368...\n",
      "Scraping nairobi, Page 369...\n",
      "Scraping nairobi, Page 370...\n",
      "Scraping nairobi, Page 371...\n",
      "Scraping nairobi, Page 372...\n",
      "Scraping nairobi, Page 373...\n",
      "Scraping nairobi, Page 374...\n",
      "Scraping nairobi, Page 375...\n",
      "Scraping nairobi, Page 376...\n",
      "Scraping nairobi, Page 377...\n",
      "Scraping nairobi, Page 378...\n",
      "Scraping nairobi, Page 379...\n",
      "Scraping nairobi, Page 380...\n",
      "Scraping nairobi, Page 381...\n",
      "Scraping nairobi, Page 382...\n",
      "Scraping nairobi, Page 383...\n",
      "Scraping nairobi, Page 384...\n",
      "Scraping nairobi, Page 385...\n",
      "Scraping nairobi, Page 386...\n",
      "Scraping nairobi, Page 387...\n",
      "Scraping nairobi, Page 388...\n",
      "Scraping nairobi, Page 389...\n",
      "Scraping nairobi, Page 390...\n",
      "Scraping nairobi, Page 391...\n",
      "Scraping nairobi, Page 392...\n",
      "Scraping nairobi, Page 393...\n",
      "Scraping nairobi, Page 394...\n",
      "Scraping nairobi, Page 395...\n",
      "Scraping nairobi, Page 396...\n",
      "Scraping nairobi, Page 397...\n",
      "Scraping nairobi, Page 398...\n",
      "Scraping nairobi, Page 399...\n",
      "Scraping nairobi, Page 400...\n",
      "Scraping nairobi, Page 401...\n",
      "Scraping nairobi, Page 402...\n",
      "Scraping nairobi, Page 403...\n",
      "Scraping nairobi, Page 404...\n",
      "Scraping nairobi, Page 405...\n",
      "Scraping nairobi, Page 406...\n",
      "Scraping nairobi, Page 407...\n",
      "Scraping nairobi, Page 408...\n",
      "Scraping nairobi, Page 409...\n",
      "Scraping nairobi, Page 410...\n",
      "Scraping nairobi, Page 411...\n",
      "Scraping nairobi, Page 412...\n",
      "Scraping nairobi, Page 413...\n",
      "Scraping nairobi, Page 414...\n",
      "Scraping nairobi, Page 415...\n",
      "Scraping nairobi, Page 416...\n",
      "Scraping nairobi, Page 417...\n",
      "Scraping nairobi, Page 418...\n",
      "Scraping nairobi, Page 419...\n",
      "Scraping nairobi, Page 420...\n",
      "Scraping nairobi, Page 421...\n",
      "Scraping nairobi, Page 422...\n",
      "Scraping nairobi, Page 423...\n",
      "Scraping nairobi, Page 424...\n",
      "Scraping nairobi, Page 425...\n",
      "Scraping nairobi, Page 426...\n",
      "Scraping nairobi, Page 427...\n",
      "Scraping nairobi, Page 428...\n",
      "Scraping nairobi, Page 429...\n",
      "Scraping nairobi, Page 430...\n",
      "Scraping nairobi, Page 431...\n",
      "Scraping nairobi, Page 432...\n",
      "Scraping nairobi, Page 433...\n",
      "Scraping nairobi, Page 434...\n",
      "Scraping nairobi, Page 435...\n",
      "Scraping nairobi, Page 436...\n",
      "Scraping nairobi, Page 437...\n",
      "Scraping nairobi, Page 438...\n",
      "Scraping nairobi, Page 439...\n",
      "Scraping nairobi, Page 440...\n",
      "Scraping nairobi, Page 441...\n",
      "Scraping nairobi, Page 442...\n",
      "Scraping nairobi, Page 443...\n",
      "Scraping nairobi, Page 444...\n",
      "Scraping nairobi, Page 445...\n",
      "Scraping nairobi, Page 446...\n",
      "Scraping nairobi, Page 447...\n",
      "Scraping nairobi, Page 448...\n",
      "Scraping nairobi, Page 449...\n",
      "Scraping nairobi, Page 450...\n",
      "Scraping nairobi, Page 451...\n",
      "Scraping nairobi, Page 452...\n",
      "Scraping nairobi, Page 453...\n",
      "Scraping nairobi, Page 454...\n",
      "Scraping nairobi, Page 455...\n",
      "Scraping nairobi, Page 456...\n",
      "Scraping nairobi, Page 457...\n",
      "Scraping nairobi, Page 458...\n",
      "Scraping nairobi, Page 459...\n",
      "Scraping nairobi, Page 460...\n",
      "Scraping nairobi, Page 461...\n",
      "Scraping nairobi, Page 462...\n",
      "Scraping nairobi, Page 463...\n",
      "Scraping nairobi, Page 464...\n",
      "Scraping nairobi, Page 465...\n",
      "Scraping nairobi, Page 466...\n",
      "Scraping nairobi, Page 467...\n",
      "Scraping nairobi, Page 468...\n",
      "Scraping nairobi, Page 469...\n",
      "Scraping nairobi, Page 470...\n",
      "Scraping nairobi, Page 471...\n",
      "Scraping nairobi, Page 472...\n",
      "Scraping nairobi, Page 473...\n",
      "Scraping nairobi, Page 474...\n",
      "Scraping nairobi, Page 475...\n",
      "Scraping nairobi, Page 476...\n",
      "Scraping nairobi, Page 477...\n",
      "Scraping nairobi, Page 478...\n",
      "Scraping nairobi, Page 479...\n",
      "Scraping nairobi, Page 480...\n",
      "Scraping nairobi, Page 481...\n",
      "Scraping nairobi, Page 482...\n",
      "Scraping nairobi, Page 483...\n",
      "Scraping nairobi, Page 484...\n",
      "Scraping nairobi, Page 485...\n",
      "Scraping nairobi, Page 486...\n",
      "Scraping nairobi, Page 487...\n",
      "Scraping nairobi, Page 488...\n",
      "Scraping nairobi, Page 489...\n",
      "Scraping nairobi, Page 490...\n",
      "Scraping nairobi, Page 491...\n",
      "Scraping nairobi, Page 492...\n",
      "Scraping nairobi, Page 493...\n",
      "Scraping nairobi, Page 494...\n",
      "Scraping nairobi, Page 495...\n",
      "Scraping nairobi, Page 496...\n",
      "Scraping nairobi, Page 497...\n",
      "Scraping nairobi, Page 498...\n",
      "Scraping nairobi, Page 499...\n",
      "Scraping nairobi, Page 500...\n",
      "Scraping nairobi, Page 501...\n",
      "Scraping nairobi, Page 502...\n",
      "Scraping nairobi, Page 503...\n",
      "Scraping nairobi, Page 504...\n",
      "Scraping nairobi, Page 505...\n",
      "Scraping nairobi, Page 506...\n",
      "Scraping nairobi, Page 507...\n",
      "Scraping nairobi, Page 508...\n",
      "Scraping nairobi, Page 509...\n",
      "Scraping nairobi, Page 510...\n",
      "Scraping nairobi, Page 511...\n",
      "Scraping nairobi, Page 512...\n",
      "Scraping nairobi, Page 513...\n",
      "Scraping nairobi, Page 514...\n",
      "Scraping nairobi, Page 515...\n",
      "Scraping nairobi, Page 516...\n",
      "Failed to fetch https://www.property24.co.ke/property-to-rent-in-nairobi-p95?Page=516, status code: 503\n",
      "Scraping complete. Data saved to 'property24_kenya_rent_listings.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to extract property details\n",
    "def extract_property_details(soup):\n",
    "    properties = []\n",
    "    \n",
    "    # Find all property listings\n",
    "    listings = soup.find_all('div', class_='sc_panelWrapper')\n",
    "    \n",
    "    for listing in listings:\n",
    "        try:\n",
    "            # Extract price\n",
    "            price = listing.find('span', class_='p24_price').text.strip()\n",
    "        except AttributeError:\n",
    "            price = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            # Extract title\n",
    "            title = listing.find('span', class_='p24_propertyTitle').text.strip()\n",
    "        except AttributeError:\n",
    "            title = 'N/A'\n",
    "\n",
    "        try:\n",
    "            # Extract property details (e.g., location)\n",
    "            details = listing.find('span', class_='p24_location').text.strip()\n",
    "        except AttributeError:\n",
    "            details = 'N/A'\n",
    "        \n",
    "        properties.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'Details': details\n",
    "        })\n",
    "        \n",
    "    return properties\n",
    "\n",
    "# Base URL template (with placeholders for province name and ID)\n",
    "base_url = 'https://www.property24.co.ke/property-to-rent-in-{}-p{}?Page={}'\n",
    "\n",
    "# List of provinces with their associated IDs\n",
    "provinces = {\n",
    "    'mombasa': 93,\n",
    "    'kwale': 85,\n",
    "    'kilifi': 80,\n",
    "    'tana river': 105,\n",
    "    'lamu': 87,\n",
    "    'taita–taveta': 104,\n",
    "    'garissa': 73,\n",
    "    'wajir': 111,\n",
    "    'mandera': 89,\n",
    "    'marsabit': 90,\n",
    "    'isiolo': 75,\n",
    "    'meru': 91,\n",
    "    'tharaka-nithi': 106,\n",
    "    'embu': 72,\n",
    "    'kitui': 84,\n",
    "    'machakos': 66,\n",
    "    'makueni': 88,\n",
    "    'nyandarua': 100,\n",
    "    'nyeri': 101,\n",
    "    'kirinyaga': 81,\n",
    "    'muranga': 94,\n",
    "    'kiambu': 79,\n",
    "    'turkana': 108,\n",
    "    'west pokot': 112,\n",
    "    'samburu': 102,\n",
    "    'trans-nzoia': 107,\n",
    "    'uasin gishu': 109,\n",
    "    'elgeyo-marakwet': 71,\n",
    "    'nandi': 97,\n",
    "    'baringo': 67,\n",
    "    'laikipia': 86,\n",
    "    'nakuru': 96,\n",
    "    'narok': 98,\n",
    "    'kajiado': 76,\n",
    "    'kericho': 78,\n",
    "    'bomet': 68,\n",
    "    'kakamega': 77,\n",
    "    'vihiga': 110,\n",
    "    'bungoma': 69,\n",
    "    'busia': 70,\n",
    "    'siaya': 103,\n",
    "    'kisumu': 83,\n",
    "    'homa bay': 74,\n",
    "    'migori': 92,\n",
    "    'kisii': 82,\n",
    "    'nyamira': 99,\n",
    "    'nairobi': 95, # Limiting Nairobi to 1000 pages later in the loop\n",
    "}\n",
    "\n",
    "# File to save progress and track last page scraped for each province\n",
    "progress_file = 'scraping_progress_rent.json'\n",
    "\n",
    "# Load progress if it exists\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, 'r') as file:\n",
    "        progress = json.load(file)\n",
    "else:\n",
    "    progress = {province: 1 for province in provinces}  # Start from page 1 for all provinces\n",
    "\n",
    "# Placeholder for all scraped properties\n",
    "all_properties = []\n",
    "\n",
    "# Function to scrape a specific province\n",
    "def scrape_province(province, province_id):\n",
    "    page_num = progress.get(province, 1)  # Start from the last saved page\n",
    "    max_pages = 1000 if province == 'nairobi' else 9999  # Limit to 1000 pages for Nairobi\n",
    "    \n",
    "    while page_num <= max_pages:\n",
    "        print(f\"Scraping {province}, Page {page_num}...\")\n",
    "        \n",
    "        # Construct the URL with the province and page number\n",
    "        url = base_url.format(province, province_id, page_num)\n",
    "        \n",
    "        # Request the page\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "            break\n",
    "        \n",
    "        # Parse the content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract property details\n",
    "        properties = extract_property_details(soup)\n",
    "        \n",
    "        if not properties:\n",
    "            print(f\"No more listings found for {province}. Stopping at page {page_num}.\")\n",
    "            break\n",
    "        \n",
    "        # Add properties to the global list\n",
    "        all_properties.extend(properties)\n",
    "        \n",
    "        # Save progress after each page\n",
    "        progress[province] = page_num\n",
    "        with open(progress_file, 'w') as file:\n",
    "            json.dump(progress, file)\n",
    "        \n",
    "        # Save data incrementally to avoid data loss\n",
    "        pd.DataFrame(all_properties).to_csv('property24_kenya_rent_listings.csv', index=False)\n",
    "        \n",
    "        # Check if a 'next' page link exists\n",
    "        next_button = soup.find('li', class_='pagelink')\n",
    "        if not next_button:\n",
    "            print(f\"Finished scraping {province} after {page_num} pages.\")\n",
    "            break\n",
    "        \n",
    "        # Delay between requests to avoid overloading the server\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Increment page number\n",
    "        page_num += 1\n",
    "\n",
    "# Loop through all provinces\n",
    "for province, province_id in provinces.items():\n",
    "    scrape_province(province, province_id)\n",
    "\n",
    "print(\"Scraping complete. Data saved to 'property24_kenya_rent_listings.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping mombasa, Page 337...\n",
      "Finished scraping mombasa after 337 pages.\n",
      "Scraping nairobi, Page 1...\n",
      "Scraping nairobi, Page 2...\n",
      "Scraping nairobi, Page 3...\n",
      "Scraping nairobi, Page 4...\n",
      "Scraping nairobi, Page 5...\n",
      "Scraping nairobi, Page 6...\n",
      "Scraping nairobi, Page 7...\n",
      "Scraping nairobi, Page 8...\n",
      "Scraping nairobi, Page 9...\n",
      "Scraping nairobi, Page 10...\n",
      "Scraping nairobi, Page 11...\n",
      "Scraping nairobi, Page 12...\n",
      "Scraping nairobi, Page 13...\n",
      "Scraping nairobi, Page 14...\n",
      "Scraping nairobi, Page 15...\n",
      "Scraping nairobi, Page 16...\n",
      "Scraping nairobi, Page 17...\n",
      "Scraping nairobi, Page 18...\n",
      "Scraping nairobi, Page 19...\n",
      "Scraping nairobi, Page 20...\n",
      "Scraping nairobi, Page 21...\n",
      "Scraping nairobi, Page 22...\n",
      "Scraping nairobi, Page 23...\n",
      "Scraping nairobi, Page 24...\n",
      "Scraping nairobi, Page 25...\n",
      "Scraping nairobi, Page 26...\n",
      "Scraping nairobi, Page 27...\n",
      "Scraping nairobi, Page 28...\n",
      "Scraping nairobi, Page 29...\n",
      "Scraping nairobi, Page 30...\n",
      "Scraping nairobi, Page 31...\n",
      "Scraping nairobi, Page 32...\n",
      "Scraping nairobi, Page 33...\n",
      "Scraping nairobi, Page 34...\n",
      "Scraping nairobi, Page 35...\n",
      "Scraping nairobi, Page 36...\n",
      "Scraping nairobi, Page 37...\n",
      "Scraping nairobi, Page 38...\n",
      "Scraping nairobi, Page 39...\n",
      "Scraping nairobi, Page 40...\n",
      "Scraping nairobi, Page 41...\n",
      "Scraping nairobi, Page 42...\n",
      "Scraping nairobi, Page 43...\n",
      "Scraping nairobi, Page 44...\n",
      "Scraping nairobi, Page 45...\n",
      "Scraping nairobi, Page 46...\n",
      "Scraping nairobi, Page 47...\n",
      "Scraping nairobi, Page 48...\n",
      "Scraping nairobi, Page 49...\n",
      "Scraping nairobi, Page 50...\n",
      "Scraping nairobi, Page 51...\n",
      "Scraping nairobi, Page 52...\n",
      "Scraping nairobi, Page 53...\n",
      "Scraping nairobi, Page 54...\n",
      "Scraping nairobi, Page 55...\n",
      "Scraping nairobi, Page 56...\n",
      "Scraping nairobi, Page 57...\n",
      "Scraping nairobi, Page 58...\n",
      "Scraping nairobi, Page 59...\n",
      "Scraping nairobi, Page 60...\n",
      "Scraping nairobi, Page 61...\n",
      "Scraping nairobi, Page 62...\n",
      "Scraping nairobi, Page 63...\n",
      "Scraping nairobi, Page 64...\n",
      "Scraping nairobi, Page 65...\n",
      "Scraping nairobi, Page 66...\n",
      "Scraping nairobi, Page 67...\n",
      "Scraping nairobi, Page 68...\n",
      "Scraping nairobi, Page 69...\n",
      "Scraping nairobi, Page 70...\n",
      "Scraping nairobi, Page 71...\n",
      "Scraping nairobi, Page 72...\n",
      "Scraping nairobi, Page 73...\n",
      "Scraping nairobi, Page 74...\n",
      "Scraping nairobi, Page 75...\n",
      "Scraping nairobi, Page 76...\n",
      "Scraping nairobi, Page 77...\n",
      "Scraping nairobi, Page 78...\n",
      "Scraping nairobi, Page 79...\n",
      "Scraping nairobi, Page 80...\n",
      "Scraping nairobi, Page 81...\n",
      "Scraping nairobi, Page 82...\n",
      "Scraping nairobi, Page 83...\n",
      "Scraping nairobi, Page 84...\n",
      "Scraping nairobi, Page 85...\n",
      "Scraping nairobi, Page 86...\n",
      "Scraping nairobi, Page 87...\n",
      "Scraping nairobi, Page 88...\n",
      "Scraping nairobi, Page 89...\n",
      "Scraping nairobi, Page 90...\n",
      "Scraping nairobi, Page 91...\n",
      "Scraping nairobi, Page 92...\n",
      "Scraping nairobi, Page 93...\n",
      "Scraping nairobi, Page 94...\n",
      "Scraping nairobi, Page 95...\n",
      "Scraping nairobi, Page 96...\n",
      "Scraping nairobi, Page 97...\n",
      "Scraping nairobi, Page 98...\n",
      "Scraping nairobi, Page 99...\n",
      "Scraping nairobi, Page 100...\n",
      "Scraping nairobi, Page 101...\n",
      "Scraping nairobi, Page 102...\n",
      "Scraping nairobi, Page 103...\n",
      "Scraping nairobi, Page 104...\n",
      "Scraping nairobi, Page 105...\n",
      "Scraping nairobi, Page 106...\n",
      "Scraping nairobi, Page 107...\n",
      "Scraping nairobi, Page 108...\n",
      "Scraping nairobi, Page 109...\n",
      "Scraping nairobi, Page 110...\n",
      "Scraping nairobi, Page 111...\n",
      "Scraping nairobi, Page 112...\n",
      "Scraping nairobi, Page 113...\n",
      "Scraping nairobi, Page 114...\n",
      "Scraping nairobi, Page 115...\n",
      "Scraping nairobi, Page 116...\n",
      "Scraping nairobi, Page 117...\n",
      "Scraping nairobi, Page 118...\n",
      "Scraping nairobi, Page 119...\n",
      "Scraping nairobi, Page 120...\n",
      "Scraping nairobi, Page 121...\n",
      "Scraping nairobi, Page 122...\n",
      "Scraping nairobi, Page 123...\n",
      "Scraping nairobi, Page 124...\n",
      "Scraping nairobi, Page 125...\n",
      "Scraping nairobi, Page 126...\n",
      "Scraping nairobi, Page 127...\n",
      "Scraping nairobi, Page 128...\n",
      "Scraping nairobi, Page 129...\n",
      "Scraping nairobi, Page 130...\n",
      "Scraping nairobi, Page 131...\n",
      "Scraping nairobi, Page 132...\n",
      "Scraping nairobi, Page 133...\n",
      "Scraping nairobi, Page 134...\n",
      "Scraping nairobi, Page 135...\n",
      "Scraping nairobi, Page 136...\n",
      "Scraping nairobi, Page 137...\n",
      "Scraping nairobi, Page 138...\n",
      "Scraping nairobi, Page 139...\n",
      "Scraping nairobi, Page 140...\n",
      "Scraping nairobi, Page 141...\n",
      "Scraping nairobi, Page 142...\n",
      "Scraping nairobi, Page 143...\n",
      "Scraping nairobi, Page 144...\n",
      "Scraping nairobi, Page 145...\n",
      "Scraping nairobi, Page 146...\n",
      "Scraping nairobi, Page 147...\n",
      "Scraping nairobi, Page 148...\n",
      "Scraping nairobi, Page 149...\n",
      "Scraping nairobi, Page 150...\n",
      "Scraping nairobi, Page 151...\n",
      "Scraping nairobi, Page 152...\n",
      "Scraping nairobi, Page 153...\n",
      "Scraping nairobi, Page 154...\n",
      "Scraping nairobi, Page 155...\n",
      "Scraping nairobi, Page 156...\n",
      "Scraping nairobi, Page 157...\n",
      "Scraping nairobi, Page 158...\n",
      "Scraping nairobi, Page 159...\n",
      "Scraping nairobi, Page 160...\n",
      "Scraping nairobi, Page 161...\n",
      "Scraping nairobi, Page 162...\n",
      "Scraping nairobi, Page 163...\n",
      "Scraping nairobi, Page 164...\n",
      "Scraping nairobi, Page 165...\n",
      "Scraping nairobi, Page 166...\n",
      "Scraping nairobi, Page 167...\n",
      "Scraping nairobi, Page 168...\n",
      "Scraping nairobi, Page 169...\n",
      "Scraping nairobi, Page 170...\n",
      "Scraping nairobi, Page 171...\n",
      "Scraping nairobi, Page 172...\n",
      "Scraping nairobi, Page 173...\n",
      "Scraping nairobi, Page 174...\n",
      "Scraping nairobi, Page 175...\n",
      "Scraping nairobi, Page 176...\n",
      "Scraping nairobi, Page 177...\n",
      "Scraping nairobi, Page 178...\n",
      "Scraping nairobi, Page 179...\n",
      "Scraping nairobi, Page 180...\n",
      "Scraping nairobi, Page 181...\n",
      "Scraping nairobi, Page 182...\n",
      "Scraping nairobi, Page 183...\n",
      "Scraping nairobi, Page 184...\n",
      "Scraping nairobi, Page 185...\n",
      "Scraping nairobi, Page 186...\n",
      "Scraping nairobi, Page 187...\n",
      "Scraping nairobi, Page 188...\n",
      "Scraping nairobi, Page 189...\n",
      "Scraping nairobi, Page 190...\n",
      "Scraping nairobi, Page 191...\n",
      "Scraping nairobi, Page 192...\n",
      "Scraping nairobi, Page 193...\n",
      "Scraping nairobi, Page 194...\n",
      "Scraping nairobi, Page 195...\n",
      "Scraping nairobi, Page 196...\n",
      "Scraping nairobi, Page 197...\n",
      "Scraping nairobi, Page 198...\n",
      "Scraping nairobi, Page 199...\n",
      "Scraping nairobi, Page 200...\n",
      "Scraping nairobi, Page 201...\n",
      "Scraping nairobi, Page 202...\n",
      "Scraping nairobi, Page 203...\n",
      "Scraping nairobi, Page 204...\n",
      "Scraping nairobi, Page 205...\n",
      "Scraping nairobi, Page 206...\n",
      "Scraping nairobi, Page 207...\n",
      "Scraping nairobi, Page 208...\n",
      "Scraping nairobi, Page 209...\n",
      "Scraping nairobi, Page 210...\n",
      "Scraping nairobi, Page 211...\n",
      "Scraping nairobi, Page 212...\n",
      "Scraping nairobi, Page 213...\n",
      "Scraping nairobi, Page 214...\n",
      "Scraping nairobi, Page 215...\n",
      "Scraping nairobi, Page 216...\n",
      "Scraping nairobi, Page 217...\n",
      "Scraping nairobi, Page 218...\n",
      "Scraping nairobi, Page 219...\n",
      "Scraping nairobi, Page 220...\n",
      "Scraping nairobi, Page 221...\n",
      "Scraping nairobi, Page 222...\n",
      "Scraping nairobi, Page 223...\n",
      "Scraping nairobi, Page 224...\n",
      "Scraping nairobi, Page 225...\n",
      "Scraping nairobi, Page 226...\n",
      "Scraping nairobi, Page 227...\n",
      "Scraping nairobi, Page 228...\n",
      "Scraping nairobi, Page 229...\n",
      "Scraping nairobi, Page 230...\n",
      "Scraping nairobi, Page 231...\n",
      "Scraping nairobi, Page 232...\n",
      "Scraping nairobi, Page 233...\n",
      "Scraping nairobi, Page 234...\n",
      "Scraping nairobi, Page 235...\n",
      "Scraping nairobi, Page 236...\n",
      "Scraping nairobi, Page 237...\n",
      "Scraping nairobi, Page 238...\n",
      "Scraping nairobi, Page 239...\n",
      "Scraping nairobi, Page 240...\n",
      "Scraping nairobi, Page 241...\n",
      "Scraping nairobi, Page 242...\n",
      "Scraping nairobi, Page 243...\n",
      "Scraping nairobi, Page 244...\n",
      "Scraping nairobi, Page 245...\n",
      "Scraping nairobi, Page 246...\n",
      "Scraping nairobi, Page 247...\n",
      "Scraping nairobi, Page 248...\n",
      "Scraping nairobi, Page 249...\n",
      "Scraping nairobi, Page 250...\n",
      "Scraping nairobi, Page 251...\n",
      "Scraping nairobi, Page 252...\n",
      "Scraping nairobi, Page 253...\n",
      "Scraping nairobi, Page 254...\n",
      "Scraping nairobi, Page 255...\n",
      "Scraping nairobi, Page 256...\n",
      "Scraping nairobi, Page 257...\n",
      "Scraping nairobi, Page 258...\n",
      "Scraping nairobi, Page 259...\n",
      "Scraping nairobi, Page 260...\n",
      "Scraping nairobi, Page 261...\n",
      "Scraping nairobi, Page 262...\n",
      "Scraping nairobi, Page 263...\n",
      "Scraping nairobi, Page 264...\n",
      "Scraping nairobi, Page 265...\n",
      "Scraping nairobi, Page 266...\n",
      "Scraping nairobi, Page 267...\n",
      "Scraping nairobi, Page 268...\n",
      "Scraping nairobi, Page 269...\n",
      "Scraping nairobi, Page 270...\n",
      "Scraping nairobi, Page 271...\n",
      "Scraping nairobi, Page 272...\n",
      "Scraping nairobi, Page 273...\n",
      "Scraping nairobi, Page 274...\n",
      "Scraping nairobi, Page 275...\n",
      "Scraping nairobi, Page 276...\n",
      "Scraping nairobi, Page 277...\n",
      "Scraping nairobi, Page 278...\n",
      "Scraping nairobi, Page 279...\n",
      "Scraping nairobi, Page 280...\n",
      "Scraping nairobi, Page 281...\n",
      "Scraping nairobi, Page 282...\n",
      "Scraping nairobi, Page 283...\n",
      "Scraping nairobi, Page 284...\n",
      "Scraping nairobi, Page 285...\n",
      "Scraping nairobi, Page 286...\n",
      "Scraping nairobi, Page 287...\n",
      "Scraping nairobi, Page 288...\n",
      "Scraping nairobi, Page 289...\n",
      "Scraping nairobi, Page 290...\n",
      "Scraping nairobi, Page 291...\n",
      "Scraping nairobi, Page 292...\n",
      "Scraping nairobi, Page 293...\n",
      "Scraping nairobi, Page 294...\n",
      "Scraping nairobi, Page 295...\n",
      "Scraping nairobi, Page 296...\n",
      "Scraping nairobi, Page 297...\n",
      "Scraping nairobi, Page 298...\n",
      "Scraping nairobi, Page 299...\n",
      "Scraping nairobi, Page 300...\n",
      "Scraping nairobi, Page 301...\n",
      "Scraping nairobi, Page 302...\n",
      "Scraping nairobi, Page 303...\n",
      "Scraping nairobi, Page 304...\n",
      "Scraping nairobi, Page 305...\n",
      "Scraping nairobi, Page 306...\n",
      "Scraping nairobi, Page 307...\n",
      "Scraping nairobi, Page 308...\n",
      "Scraping nairobi, Page 309...\n",
      "Scraping nairobi, Page 310...\n",
      "Scraping nairobi, Page 311...\n",
      "Scraping nairobi, Page 312...\n",
      "Scraping nairobi, Page 313...\n",
      "Scraping nairobi, Page 314...\n",
      "Scraping nairobi, Page 315...\n",
      "Scraping nairobi, Page 316...\n",
      "Scraping nairobi, Page 317...\n",
      "Scraping nairobi, Page 318...\n",
      "Scraping nairobi, Page 319...\n",
      "Scraping nairobi, Page 320...\n",
      "Scraping nairobi, Page 321...\n",
      "Scraping nairobi, Page 322...\n",
      "Scraping nairobi, Page 323...\n",
      "Scraping nairobi, Page 324...\n",
      "Scraping nairobi, Page 325...\n",
      "Scraping nairobi, Page 326...\n",
      "Scraping nairobi, Page 327...\n",
      "Scraping nairobi, Page 328...\n",
      "Scraping nairobi, Page 329...\n",
      "Scraping nairobi, Page 330...\n",
      "Scraping nairobi, Page 331...\n",
      "Scraping nairobi, Page 332...\n",
      "Scraping nairobi, Page 333...\n",
      "Scraping nairobi, Page 334...\n",
      "Scraping nairobi, Page 335...\n",
      "Scraping nairobi, Page 336...\n",
      "Scraping nairobi, Page 337...\n",
      "Scraping nairobi, Page 338...\n",
      "Scraping nairobi, Page 339...\n",
      "Scraping nairobi, Page 340...\n",
      "Scraping nairobi, Page 341...\n",
      "Scraping nairobi, Page 342...\n",
      "Scraping nairobi, Page 343...\n",
      "Scraping nairobi, Page 344...\n",
      "Scraping nairobi, Page 345...\n",
      "Scraping nairobi, Page 346...\n",
      "Scraping nairobi, Page 347...\n",
      "Scraping nairobi, Page 348...\n",
      "Scraping nairobi, Page 349...\n",
      "Scraping nairobi, Page 350...\n",
      "Scraping nairobi, Page 351...\n",
      "Scraping nairobi, Page 352...\n",
      "Scraping nairobi, Page 353...\n",
      "Scraping nairobi, Page 354...\n",
      "Scraping nairobi, Page 355...\n",
      "Scraping nairobi, Page 356...\n",
      "Scraping nairobi, Page 357...\n",
      "Scraping nairobi, Page 358...\n",
      "Scraping nairobi, Page 359...\n",
      "Scraping nairobi, Page 360...\n",
      "Scraping nairobi, Page 361...\n",
      "Scraping nairobi, Page 362...\n",
      "Scraping nairobi, Page 363...\n",
      "Scraping nairobi, Page 364...\n",
      "Scraping nairobi, Page 365...\n",
      "Scraping nairobi, Page 366...\n",
      "Scraping nairobi, Page 367...\n",
      "Scraping nairobi, Page 368...\n",
      "Scraping nairobi, Page 369...\n",
      "Scraping nairobi, Page 370...\n",
      "Scraping nairobi, Page 371...\n",
      "Scraping nairobi, Page 372...\n",
      "Scraping nairobi, Page 373...\n",
      "Scraping nairobi, Page 374...\n",
      "Scraping nairobi, Page 375...\n",
      "Scraping nairobi, Page 376...\n",
      "Scraping nairobi, Page 377...\n",
      "Scraping nairobi, Page 378...\n",
      "Scraping nairobi, Page 379...\n",
      "Scraping nairobi, Page 380...\n",
      "Scraping nairobi, Page 381...\n",
      "Scraping nairobi, Page 382...\n",
      "Scraping nairobi, Page 383...\n",
      "Scraping nairobi, Page 384...\n",
      "Scraping nairobi, Page 385...\n",
      "Scraping nairobi, Page 386...\n",
      "Scraping nairobi, Page 387...\n",
      "Scraping nairobi, Page 388...\n",
      "Scraping nairobi, Page 389...\n",
      "Scraping nairobi, Page 390...\n",
      "Scraping nairobi, Page 391...\n",
      "Scraping nairobi, Page 392...\n",
      "Scraping nairobi, Page 393...\n",
      "Scraping nairobi, Page 394...\n",
      "Scraping nairobi, Page 395...\n",
      "Scraping nairobi, Page 396...\n",
      "Scraping nairobi, Page 397...\n",
      "Scraping nairobi, Page 398...\n",
      "Scraping nairobi, Page 399...\n",
      "Scraping nairobi, Page 400...\n",
      "Scraping nairobi, Page 401...\n",
      "Scraping nairobi, Page 402...\n",
      "Scraping nairobi, Page 403...\n",
      "Scraping nairobi, Page 404...\n",
      "Scraping nairobi, Page 405...\n",
      "Scraping nairobi, Page 406...\n",
      "Scraping nairobi, Page 407...\n",
      "Scraping nairobi, Page 408...\n",
      "Scraping nairobi, Page 409...\n",
      "Scraping nairobi, Page 410...\n",
      "Scraping nairobi, Page 411...\n",
      "Scraping nairobi, Page 412...\n",
      "Scraping nairobi, Page 413...\n",
      "Scraping nairobi, Page 414...\n",
      "Scraping nairobi, Page 415...\n",
      "Scraping nairobi, Page 416...\n",
      "Scraping nairobi, Page 417...\n",
      "Scraping nairobi, Page 418...\n",
      "Scraping nairobi, Page 419...\n",
      "Scraping nairobi, Page 420...\n",
      "Scraping nairobi, Page 421...\n",
      "Scraping nairobi, Page 422...\n",
      "Scraping nairobi, Page 423...\n",
      "Scraping nairobi, Page 424...\n",
      "Scraping nairobi, Page 425...\n",
      "Scraping nairobi, Page 426...\n",
      "Scraping nairobi, Page 427...\n",
      "Scraping nairobi, Page 428...\n",
      "Scraping nairobi, Page 429...\n",
      "Scraping nairobi, Page 430...\n",
      "Scraping nairobi, Page 431...\n",
      "Scraping nairobi, Page 432...\n",
      "Scraping nairobi, Page 433...\n",
      "Scraping nairobi, Page 434...\n",
      "Scraping nairobi, Page 435...\n",
      "Scraping nairobi, Page 436...\n",
      "Scraping nairobi, Page 437...\n",
      "Scraping nairobi, Page 438...\n",
      "Scraping nairobi, Page 439...\n",
      "Scraping nairobi, Page 440...\n",
      "Scraping nairobi, Page 441...\n",
      "Scraping nairobi, Page 442...\n",
      "Scraping nairobi, Page 443...\n",
      "Scraping nairobi, Page 444...\n",
      "Scraping nairobi, Page 445...\n",
      "Scraping nairobi, Page 446...\n",
      "Scraping nairobi, Page 447...\n",
      "Scraping nairobi, Page 448...\n",
      "Scraping nairobi, Page 449...\n",
      "Scraping nairobi, Page 450...\n",
      "Scraping nairobi, Page 451...\n",
      "Scraping nairobi, Page 452...\n",
      "Scraping nairobi, Page 453...\n",
      "Scraping nairobi, Page 454...\n",
      "Scraping nairobi, Page 455...\n",
      "Scraping nairobi, Page 456...\n",
      "Scraping nairobi, Page 457...\n",
      "Scraping nairobi, Page 458...\n",
      "Scraping nairobi, Page 459...\n",
      "Scraping nairobi, Page 460...\n",
      "Scraping nairobi, Page 461...\n",
      "Scraping nairobi, Page 462...\n",
      "Scraping nairobi, Page 463...\n",
      "Scraping nairobi, Page 464...\n",
      "Scraping nairobi, Page 465...\n",
      "Scraping nairobi, Page 466...\n",
      "Scraping nairobi, Page 467...\n",
      "Scraping nairobi, Page 468...\n",
      "Scraping nairobi, Page 469...\n",
      "Scraping nairobi, Page 470...\n",
      "Scraping nairobi, Page 471...\n",
      "Scraping nairobi, Page 472...\n",
      "Scraping nairobi, Page 473...\n",
      "Scraping nairobi, Page 474...\n",
      "Scraping nairobi, Page 475...\n",
      "Scraping nairobi, Page 476...\n",
      "Scraping nairobi, Page 477...\n",
      "Scraping nairobi, Page 478...\n",
      "Scraping nairobi, Page 479...\n",
      "Scraping nairobi, Page 480...\n",
      "Scraping nairobi, Page 481...\n",
      "Scraping nairobi, Page 482...\n",
      "Scraping nairobi, Page 483...\n",
      "Scraping nairobi, Page 484...\n",
      "Scraping nairobi, Page 485...\n",
      "Scraping nairobi, Page 486...\n",
      "Scraping nairobi, Page 487...\n",
      "Scraping nairobi, Page 488...\n",
      "Scraping nairobi, Page 489...\n",
      "Scraping nairobi, Page 490...\n",
      "Scraping nairobi, Page 491...\n",
      "Scraping nairobi, Page 492...\n",
      "Scraping nairobi, Page 493...\n",
      "Scraping nairobi, Page 494...\n",
      "Scraping nairobi, Page 495...\n",
      "Scraping nairobi, Page 496...\n",
      "Scraping nairobi, Page 497...\n",
      "Scraping nairobi, Page 498...\n",
      "Scraping nairobi, Page 499...\n",
      "Scraping nairobi, Page 500...\n",
      "Scraping nairobi, Page 501...\n",
      "Scraping nairobi, Page 502...\n",
      "Scraping nairobi, Page 503...\n",
      "Scraping nairobi, Page 504...\n",
      "Scraping nairobi, Page 505...\n",
      "Scraping nairobi, Page 506...\n",
      "Scraping nairobi, Page 507...\n",
      "Scraping nairobi, Page 508...\n",
      "Scraping nairobi, Page 509...\n",
      "Scraping nairobi, Page 510...\n",
      "Scraping nairobi, Page 511...\n",
      "Scraping nairobi, Page 512...\n",
      "Scraping nairobi, Page 513...\n",
      "Scraping nairobi, Page 514...\n",
      "Scraping nairobi, Page 515...\n",
      "Scraping nairobi, Page 516...\n",
      "Scraping nairobi, Page 517...\n",
      "Scraping nairobi, Page 518...\n",
      "Scraping nairobi, Page 519...\n",
      "Scraping nairobi, Page 520...\n",
      "Scraping nairobi, Page 521...\n",
      "Scraping nairobi, Page 522...\n",
      "Scraping nairobi, Page 523...\n",
      "Scraping nairobi, Page 524...\n",
      "Scraping nairobi, Page 525...\n",
      "Scraping nairobi, Page 526...\n",
      "Scraping nairobi, Page 527...\n",
      "Scraping nairobi, Page 528...\n",
      "Scraping nairobi, Page 529...\n",
      "Scraping nairobi, Page 530...\n",
      "Scraping nairobi, Page 531...\n",
      "Scraping nairobi, Page 532...\n",
      "Scraping nairobi, Page 533...\n",
      "Scraping nairobi, Page 534...\n",
      "Scraping nairobi, Page 535...\n",
      "Scraping nairobi, Page 536...\n",
      "Scraping nairobi, Page 537...\n",
      "Scraping nairobi, Page 538...\n",
      "Scraping nairobi, Page 539...\n",
      "Scraping nairobi, Page 540...\n",
      "Scraping nairobi, Page 541...\n",
      "Scraping nairobi, Page 542...\n",
      "Scraping nairobi, Page 543...\n",
      "Scraping nairobi, Page 544...\n",
      "Scraping nairobi, Page 545...\n",
      "Scraping nairobi, Page 546...\n",
      "Scraping nairobi, Page 547...\n",
      "Scraping nairobi, Page 548...\n",
      "Scraping nairobi, Page 549...\n",
      "Scraping nairobi, Page 550...\n",
      "Scraping nairobi, Page 551...\n",
      "Scraping nairobi, Page 552...\n",
      "Scraping nairobi, Page 553...\n",
      "Scraping nairobi, Page 554...\n",
      "Scraping nairobi, Page 555...\n",
      "Scraping nairobi, Page 556...\n",
      "Scraping nairobi, Page 557...\n",
      "Scraping nairobi, Page 558...\n",
      "Scraping nairobi, Page 559...\n",
      "Scraping nairobi, Page 560...\n",
      "Scraping nairobi, Page 561...\n",
      "Scraping nairobi, Page 562...\n",
      "Scraping nairobi, Page 563...\n",
      "Scraping nairobi, Page 564...\n",
      "Scraping nairobi, Page 565...\n",
      "Scraping nairobi, Page 566...\n",
      "Scraping nairobi, Page 567...\n",
      "Scraping nairobi, Page 568...\n",
      "Scraping nairobi, Page 569...\n",
      "Scraping nairobi, Page 570...\n",
      "Scraping nairobi, Page 571...\n",
      "Scraping nairobi, Page 572...\n",
      "Scraping nairobi, Page 573...\n",
      "Scraping nairobi, Page 574...\n",
      "Scraping nairobi, Page 575...\n",
      "Scraping nairobi, Page 576...\n",
      "Scraping nairobi, Page 577...\n",
      "Scraping nairobi, Page 578...\n",
      "Scraping nairobi, Page 579...\n",
      "Scraping nairobi, Page 580...\n",
      "Scraping nairobi, Page 581...\n",
      "Scraping nairobi, Page 582...\n",
      "Scraping nairobi, Page 583...\n",
      "Scraping nairobi, Page 584...\n",
      "Scraping nairobi, Page 585...\n",
      "Scraping nairobi, Page 586...\n",
      "Scraping nairobi, Page 587...\n",
      "Scraping nairobi, Page 588...\n",
      "Scraping nairobi, Page 589...\n",
      "Scraping nairobi, Page 590...\n",
      "Scraping nairobi, Page 591...\n",
      "Scraping nairobi, Page 592...\n",
      "Scraping nairobi, Page 593...\n",
      "Scraping nairobi, Page 594...\n",
      "Scraping nairobi, Page 595...\n",
      "Scraping nairobi, Page 596...\n",
      "Scraping nairobi, Page 597...\n",
      "Scraping nairobi, Page 598...\n",
      "Scraping nairobi, Page 599...\n",
      "Scraping nairobi, Page 600...\n",
      "Scraping nairobi, Page 601...\n",
      "Scraping nairobi, Page 602...\n",
      "Scraping nairobi, Page 603...\n",
      "Scraping nairobi, Page 604...\n",
      "Scraping nairobi, Page 605...\n",
      "Scraping nairobi, Page 606...\n",
      "Scraping nairobi, Page 607...\n",
      "Scraping nairobi, Page 608...\n",
      "Scraping nairobi, Page 609...\n",
      "Scraping nairobi, Page 610...\n",
      "Scraping nairobi, Page 611...\n",
      "Scraping nairobi, Page 612...\n",
      "Scraping nairobi, Page 613...\n",
      "Scraping nairobi, Page 614...\n",
      "Scraping nairobi, Page 615...\n",
      "Scraping nairobi, Page 616...\n",
      "Scraping nairobi, Page 617...\n",
      "Scraping nairobi, Page 618...\n",
      "Scraping nairobi, Page 619...\n",
      "Scraping nairobi, Page 620...\n",
      "Scraping nairobi, Page 621...\n",
      "Scraping nairobi, Page 622...\n",
      "Scraping nairobi, Page 623...\n",
      "Scraping nairobi, Page 624...\n",
      "Scraping nairobi, Page 625...\n",
      "Scraping nairobi, Page 626...\n",
      "Scraping nairobi, Page 627...\n",
      "Scraping nairobi, Page 628...\n",
      "Scraping nairobi, Page 629...\n",
      "Scraping nairobi, Page 630...\n",
      "Scraping nairobi, Page 631...\n",
      "Scraping nairobi, Page 632...\n",
      "Scraping nairobi, Page 633...\n",
      "Scraping nairobi, Page 634...\n",
      "Scraping nairobi, Page 635...\n",
      "Scraping nairobi, Page 636...\n",
      "Scraping nairobi, Page 637...\n",
      "Scraping nairobi, Page 638...\n",
      "Scraping nairobi, Page 639...\n",
      "Scraping nairobi, Page 640...\n",
      "Scraping nairobi, Page 641...\n",
      "Scraping nairobi, Page 642...\n",
      "Scraping nairobi, Page 643...\n",
      "Scraping nairobi, Page 644...\n",
      "Scraping nairobi, Page 645...\n",
      "Scraping nairobi, Page 646...\n",
      "Scraping nairobi, Page 647...\n",
      "Scraping nairobi, Page 648...\n",
      "Scraping nairobi, Page 649...\n",
      "Scraping nairobi, Page 650...\n",
      "Scraping nairobi, Page 651...\n",
      "Scraping nairobi, Page 652...\n",
      "Scraping nairobi, Page 653...\n",
      "Scraping nairobi, Page 654...\n",
      "Scraping nairobi, Page 655...\n",
      "Scraping nairobi, Page 656...\n",
      "Scraping nairobi, Page 657...\n",
      "Scraping nairobi, Page 658...\n",
      "Scraping nairobi, Page 659...\n",
      "Scraping nairobi, Page 660...\n",
      "Scraping nairobi, Page 661...\n",
      "Scraping nairobi, Page 662...\n",
      "Scraping nairobi, Page 663...\n",
      "Scraping nairobi, Page 664...\n",
      "Scraping nairobi, Page 665...\n",
      "Scraping nairobi, Page 666...\n",
      "Scraping nairobi, Page 667...\n",
      "Scraping nairobi, Page 668...\n",
      "Scraping nairobi, Page 669...\n",
      "Scraping nairobi, Page 670...\n",
      "Scraping nairobi, Page 671...\n",
      "Scraping nairobi, Page 672...\n",
      "Scraping nairobi, Page 673...\n",
      "Scraping nairobi, Page 674...\n",
      "Scraping nairobi, Page 675...\n",
      "Scraping nairobi, Page 676...\n",
      "Scraping nairobi, Page 677...\n",
      "Scraping nairobi, Page 678...\n",
      "Scraping nairobi, Page 679...\n",
      "Scraping nairobi, Page 680...\n",
      "Scraping nairobi, Page 681...\n",
      "Scraping nairobi, Page 682...\n",
      "Scraping nairobi, Page 683...\n",
      "Scraping nairobi, Page 684...\n",
      "Scraping nairobi, Page 685...\n",
      "Scraping nairobi, Page 686...\n",
      "Scraping nairobi, Page 687...\n",
      "Scraping nairobi, Page 688...\n",
      "Scraping nairobi, Page 689...\n",
      "Scraping nairobi, Page 690...\n",
      "Scraping nairobi, Page 691...\n",
      "Scraping nairobi, Page 692...\n",
      "Scraping nairobi, Page 693...\n",
      "Scraping nairobi, Page 694...\n",
      "Scraping nairobi, Page 695...\n",
      "Scraping nairobi, Page 696...\n",
      "Scraping nairobi, Page 697...\n",
      "Scraping nairobi, Page 698...\n",
      "Scraping nairobi, Page 699...\n",
      "Scraping nairobi, Page 700...\n",
      "Scraping nairobi, Page 701...\n",
      "Scraping nairobi, Page 702...\n",
      "Scraping nairobi, Page 703...\n",
      "Scraping nairobi, Page 704...\n",
      "Scraping nairobi, Page 705...\n",
      "Scraping nairobi, Page 706...\n",
      "Scraping nairobi, Page 707...\n",
      "Scraping nairobi, Page 708...\n",
      "Scraping nairobi, Page 709...\n",
      "Scraping nairobi, Page 710...\n",
      "Scraping nairobi, Page 711...\n",
      "Scraping nairobi, Page 712...\n",
      "Scraping nairobi, Page 713...\n",
      "Scraping nairobi, Page 714...\n",
      "Scraping nairobi, Page 715...\n",
      "Scraping nairobi, Page 716...\n",
      "Scraping nairobi, Page 717...\n",
      "Scraping nairobi, Page 718...\n",
      "Scraping nairobi, Page 719...\n",
      "Scraping nairobi, Page 720...\n",
      "Scraping nairobi, Page 721...\n",
      "Scraping nairobi, Page 722...\n",
      "Scraping nairobi, Page 723...\n",
      "Scraping nairobi, Page 724...\n",
      "Scraping nairobi, Page 725...\n",
      "Scraping nairobi, Page 726...\n",
      "Scraping nairobi, Page 727...\n",
      "Scraping nairobi, Page 728...\n",
      "Scraping nairobi, Page 729...\n",
      "Scraping nairobi, Page 730...\n",
      "Scraping nairobi, Page 731...\n",
      "Scraping nairobi, Page 732...\n",
      "Scraping nairobi, Page 733...\n",
      "Scraping nairobi, Page 734...\n",
      "Scraping nairobi, Page 735...\n",
      "Scraping nairobi, Page 736...\n",
      "Scraping nairobi, Page 737...\n",
      "Scraping nairobi, Page 738...\n",
      "Scraping nairobi, Page 739...\n",
      "Scraping nairobi, Page 740...\n",
      "Scraping nairobi, Page 741...\n",
      "Scraping nairobi, Page 742...\n",
      "Scraping nairobi, Page 743...\n",
      "Scraping nairobi, Page 744...\n",
      "Scraping nairobi, Page 745...\n",
      "Scraping nairobi, Page 746...\n",
      "Scraping nairobi, Page 747...\n",
      "Scraping nairobi, Page 748...\n",
      "Scraping nairobi, Page 749...\n",
      "Scraping nairobi, Page 750...\n",
      "Scraping nairobi, Page 751...\n",
      "Scraping nairobi, Page 752...\n",
      "Scraping nairobi, Page 753...\n",
      "Scraping nairobi, Page 754...\n",
      "Scraping nairobi, Page 755...\n",
      "Scraping nairobi, Page 756...\n",
      "Scraping nairobi, Page 757...\n",
      "Scraping nairobi, Page 758...\n",
      "Scraping nairobi, Page 759...\n",
      "Scraping nairobi, Page 760...\n",
      "Scraping nairobi, Page 761...\n",
      "Scraping nairobi, Page 762...\n",
      "Scraping nairobi, Page 763...\n",
      "Scraping nairobi, Page 764...\n",
      "Scraping nairobi, Page 765...\n",
      "Scraping nairobi, Page 766...\n",
      "Scraping nairobi, Page 767...\n",
      "Scraping nairobi, Page 768...\n",
      "Scraping nairobi, Page 769...\n",
      "Scraping nairobi, Page 770...\n",
      "Scraping nairobi, Page 771...\n",
      "Scraping nairobi, Page 772...\n",
      "Scraping nairobi, Page 773...\n",
      "Scraping nairobi, Page 774...\n",
      "Scraping nairobi, Page 775...\n",
      "Scraping nairobi, Page 776...\n",
      "Scraping nairobi, Page 777...\n",
      "Scraping nairobi, Page 778...\n",
      "Scraping nairobi, Page 779...\n",
      "Scraping nairobi, Page 780...\n",
      "Scraping nairobi, Page 781...\n",
      "Scraping nairobi, Page 782...\n",
      "Scraping nairobi, Page 783...\n",
      "Scraping nairobi, Page 784...\n",
      "Scraping nairobi, Page 785...\n",
      "Scraping nairobi, Page 786...\n",
      "Scraping nairobi, Page 787...\n",
      "Scraping nairobi, Page 788...\n",
      "Scraping nairobi, Page 789...\n",
      "Scraping nairobi, Page 790...\n",
      "Scraping nairobi, Page 791...\n",
      "Scraping nairobi, Page 792...\n",
      "Scraping nairobi, Page 793...\n",
      "Scraping nairobi, Page 794...\n",
      "Scraping nairobi, Page 795...\n",
      "Scraping nairobi, Page 796...\n",
      "Scraping nairobi, Page 797...\n",
      "Scraping nairobi, Page 798...\n",
      "Scraping nairobi, Page 799...\n",
      "Scraping nairobi, Page 800...\n",
      "Scraping nairobi, Page 801...\n",
      "Scraping nairobi, Page 802...\n",
      "Scraping nairobi, Page 803...\n",
      "Scraping nairobi, Page 804...\n",
      "Scraping nairobi, Page 805...\n",
      "Scraping nairobi, Page 806...\n",
      "Scraping nairobi, Page 807...\n",
      "Scraping nairobi, Page 808...\n",
      "Scraping nairobi, Page 809...\n",
      "Scraping nairobi, Page 810...\n",
      "Scraping nairobi, Page 811...\n",
      "Scraping nairobi, Page 812...\n",
      "Scraping nairobi, Page 813...\n",
      "Scraping nairobi, Page 814...\n",
      "Scraping nairobi, Page 815...\n",
      "Scraping nairobi, Page 816...\n",
      "Scraping nairobi, Page 817...\n",
      "Scraping nairobi, Page 818...\n",
      "Scraping nairobi, Page 819...\n",
      "Scraping nairobi, Page 820...\n",
      "Scraping nairobi, Page 821...\n",
      "Scraping nairobi, Page 822...\n",
      "Scraping nairobi, Page 823...\n",
      "Scraping nairobi, Page 824...\n",
      "Scraping nairobi, Page 825...\n",
      "Scraping nairobi, Page 826...\n",
      "Scraping nairobi, Page 827...\n",
      "Scraping nairobi, Page 828...\n",
      "Scraping nairobi, Page 829...\n",
      "Scraping nairobi, Page 830...\n",
      "Scraping nairobi, Page 831...\n",
      "Scraping nairobi, Page 832...\n",
      "Scraping nairobi, Page 833...\n",
      "Scraping nairobi, Page 834...\n",
      "Scraping nairobi, Page 835...\n",
      "Scraping nairobi, Page 836...\n",
      "Scraping nairobi, Page 837...\n",
      "Scraping nairobi, Page 838...\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.property24.co.ke', port=443): Max retries exceeded with url: /property-for-sale-in-nairobi-p95?Page=838 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x10c926d40>: Failed to resolve 'www.property24.co.ke' ([Errno 8] nodename nor servname provided, or not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connection.py:615\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x10c926d40>: Failed to resolve 'www.property24.co.ke' ([Errno 8] nodename nor servname provided, or not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.property24.co.ke', port=443): Max retries exceeded with url: /property-for-sale-in-nairobi-p95?Page=838 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x10c926d40>: Failed to resolve 'www.property24.co.ke' ([Errno 8] nodename nor servname provided, or not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 118\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Loop through all provinces\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m province, province_id \u001b[38;5;129;01min\u001b[39;00m provinces\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 118\u001b[0m     \u001b[43mscrape_province\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovince\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovince_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping complete. Data saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty24_kenya_sale_listings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 76\u001b[0m, in \u001b[0;36mscrape_province\u001b[0;34m(province, province_id)\u001b[0m\n\u001b[1;32m     73\u001b[0m url \u001b[38;5;241m=\u001b[39m base_url\u001b[38;5;241m.\u001b[39mformat(province, province_id, page_num)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Request the page\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/spark_env/lib/python3.10/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.property24.co.ke', port=443): Max retries exceeded with url: /property-for-sale-in-nairobi-p95?Page=838 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x10c926d40>: Failed to resolve 'www.property24.co.ke' ([Errno 8] nodename nor servname provided, or not known)\"))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to extract property details\n",
    "def extract_property_details(soup):\n",
    "    properties = []\n",
    "    \n",
    "    # Find all property listings\n",
    "    listings = soup.find_all('div', class_='sc_panelWrapper')\n",
    "    \n",
    "    for listing in listings:\n",
    "        try:\n",
    "            # Extract price\n",
    "            price = listing.find('span', class_='p24_price').text.strip()\n",
    "        except AttributeError:\n",
    "            price = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            # Extract title\n",
    "            title = listing.find('span', class_='p24_propertyTitle').text.strip()\n",
    "        except AttributeError:\n",
    "            title = 'N/A'\n",
    "\n",
    "        try:\n",
    "            # Extract property details (e.g., location)\n",
    "            details = listing.find('span', class_='p24_location').text.strip()\n",
    "        except AttributeError:\n",
    "            details = 'N/A'\n",
    "        \n",
    "        properties.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'Details': details\n",
    "        })\n",
    "        \n",
    "    return properties\n",
    "\n",
    "# Base URL template (with placeholders for province name and ID)\n",
    "base_url = 'https://www.property24.co.ke/property-for-sale-in-{}-p{}?Page={}'\n",
    "\n",
    "# List of provinces with their associated IDs\n",
    "provinces = {\n",
    "    'mombasa': 93,\n",
    "    'nairobi': 95, # Limiting Nairobi to 1000 pages later in the loop\n",
    "}\n",
    "\n",
    "# File to save progress and track last page scraped for each province\n",
    "progress_file = 'scraping_progress_sale.json'\n",
    "\n",
    "# Load progress if it exists\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, 'r') as file:\n",
    "        progress = json.load(file)\n",
    "else:\n",
    "    progress = {province: 1 for province in provinces}  # Start from page 1 for all provinces\n",
    "\n",
    "# Placeholder for all scraped properties\n",
    "all_properties = []\n",
    "\n",
    "# Function to scrape a specific province\n",
    "def scrape_province(province, province_id):\n",
    "    page_num = progress.get(province, 1)  # Start from the last saved page\n",
    "    max_pages = 1000 if province == 'nairobi' else 9999  # Limit to 1000 pages for Nairobi\n",
    "    \n",
    "    while page_num <= max_pages:\n",
    "        print(f\"Scraping {province}, Page {page_num}...\")\n",
    "        \n",
    "        # Construct the URL with the province and page number\n",
    "        url = base_url.format(province, province_id, page_num)\n",
    "        \n",
    "        # Request the page\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "            break\n",
    "        \n",
    "        # Parse the content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract property details\n",
    "        properties = extract_property_details(soup)\n",
    "        \n",
    "        if not properties:\n",
    "            print(f\"No more listings found for {province}. Stopping at page {page_num}.\")\n",
    "            break\n",
    "        \n",
    "        # Add properties to the global list\n",
    "        all_properties.extend(properties)\n",
    "        \n",
    "        # Save progress after each page\n",
    "        progress[province] = page_num\n",
    "        with open(progress_file, 'w') as file:\n",
    "            json.dump(progress, file)\n",
    "        \n",
    "        # Save data incrementally to avoid data loss\n",
    "        pd.DataFrame(all_properties).to_csv('property24_kenya_sale_listings.csv', index=False)\n",
    "        \n",
    "        # Check if a 'next' page link exists\n",
    "        next_button = soup.find('li', class_='pagelink')\n",
    "        if not next_button:\n",
    "            print(f\"Finished scraping {province} after {page_num} pages.\")\n",
    "            break\n",
    "        \n",
    "        # Delay between requests to avoid overloading the server\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Increment page number\n",
    "        page_num += 1\n",
    "\n",
    "# Loop through all provinces\n",
    "for province, province_id in provinces.items():\n",
    "    scrape_province(province, province_id)\n",
    "\n",
    "print(\"Scraping complete. Data saved to 'property24_kenya_sale_listings.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
